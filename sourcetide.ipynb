{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPefcY4PC9fX1wR+UrPIScN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monacofj/sourcetide/blob/main/sourcetide.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SourceTide - Analytics for collaborative development dynamics**\n",
        "---\n",
        "*Copyright (c) 2025, Monaco F. J. <monaco@usp.br> </br>\n",
        "This is free software distributed under the GNU General Public License vr. 3.0.*\n",
        "\n",
        "*Open Source/Science, CCOS-ICMC - University of São Paulo.*\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4vaGsuiC5L-t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# USER SETUP"
      ],
      "metadata": {
        "id": "4OT7pykvIwBe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Repository"
      ],
      "metadata": {
        "id": "OEeLJm0UfNQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cellname : which-repo\n",
        "\n",
        "# Repository identification\n",
        "\n",
        "owner = \"fossguild\"  # <--- Replace with the actual owner username\n",
        "repository_name = \"naja\"  # <--- Replace with the actual repository name\n",
        "\n",
        "# GitHub Token\n",
        "#\n",
        "# To access the GitHub API, you'll need a personal access token. You can\n",
        "# generate one in your GitHub account settings under \"Developer settings\" >\n",
        "# \"Personal  access tokens\". Grant the token the necessary permissions\n",
        "# (e.g., `repo` scope for full control or more specific scopes like\n",
        "# `public_repo` for public repositories). In Colab, you can store your token\n",
        "# securely in the secrets manager under the key icon in the left panel.\n",
        "# Add a new secret with the name `GITHUB_TOKEN` and paste your token as\n",
        "# the value.\n"
      ],
      "metadata": {
        "id": "borUqKOx6vVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Period"
      ],
      "metadata": {
        "id": "pbsIQx1ZImvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cellname : period\n",
        "\n",
        "# Choose the period of analysis in weeks.\n",
        "\n",
        "num_weeks = 1"
      ],
      "metadata": {
        "id": "CFlxD0ttHmNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Report"
      ],
      "metadata": {
        "id": "hrWp8pFDa4N0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cellname : report\n",
        "\n",
        "# Should an HTML report file be generated?\n",
        "# Answer with 'y', 'Y' (for Yes) or 'n', 'N' (for No)\n",
        "\n",
        "generate_report_value = 'y'\n",
        "\n",
        "# Base path where the report folder will be saved (Google Drive)\n",
        "report_path = 'My Drive/'\n"
      ],
      "metadata": {
        "id": "OnyMCQQSVi00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80e4097c"
      },
      "source": [
        "try:\n",
        "    repo = g.get_user(owner).get_repo(repository_name)\n",
        "    print(f\"Repository Name: {repo.name}\")\n",
        "    print(f\"Repository Description: {repo.description}\")\n",
        "    print(f\"Repository URL: {repo.html_url}\")\n",
        "    print(f\"Stars: {repo.stargazers_count}\")\n",
        "    print(f\"Forks: {repo.forks_count}\")\n",
        "    print(f\"Created At: {repo.created_at}\")\n",
        "    print(f\"Last Updated At: {repo.updated_at}\")\n",
        "\n",
        "    # The analysis_run_date is now defined in the 'Analysis Run Date' cell in USER SETUP.\n",
        "    # This cell will only print it.\n",
        "    print(f\"Analysis Run Date: {analysis_run_date}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error fetching repository information: {e}\")\n",
        "    # If you see an error here AFTER replacing the owner and repository_name,\n",
        "    # please copy and paste the full error message so I can assist you.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f69907cc"
      },
      "source": [
        "## Análise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "686c6fdb"
      },
      "source": [
        "# cellname : analysis-date\n",
        "from datetime import datetime\n",
        "\n",
        "# Define the single source of truth for the analysis run date\n",
        "analysis_run_date = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "print(f\"Analysis started at: {analysis_run_date}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Score"
      ],
      "metadata": {
        "id": "ZzMiAeA1c1GF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cellname : score-parameters\n",
        "\n",
        "## Chosse the parameters to be used to compute the contribution score\n",
        "##\n",
        "## activity = A * (REMI>0)   +   (1-A) (RDMI>0)\n",
        "## reward   = R *  REMI      +   (1-R)  RDMI\n",
        "## score    = S * activity   +   (1-S)  reward\n",
        "##\n",
        "## Interpretation:\n",
        "##\n",
        "## * activity a binary weighted measure of minimal participation in both\n",
        "##            discussions and coding. The parameter A says how much each\n",
        "##            dimension is important: A=1 means only discussion counts;\n",
        "##            A=0 means only coding counts; A=0.5 both count equally.\n",
        "##            Activity varies from 0 to 1.\n",
        "##\n",
        "##  * reward  is a weighted measure of participation in both discussion\n",
        "##            and coding. The parameter R says how much each dimension is\n",
        "##            important: R=0 means only discussion counts; R=1 means only\n",
        "##            coding counts; R=0.5 both count equally.\n",
        "##            Reward valies from 0 to 1.\n",
        "##\n",
        "##  * score   is a weighted combination of activity and reward. The parameter\n",
        "##            S says which is more imporant: S=1 means that we're exclusively\n",
        "##            interested in the fact that there was any participation, and\n",
        "##            not in how intensive this participation was. S=0 means that the\n",
        "##            score is proportional to the participation intensity. S=0.5\n",
        "##            mean that half of the score is based on whether was any\n",
        "##            participation, and the other half is a bonification for the\n",
        "##            intensity of the work done.\n",
        "\n",
        "A_factor = 0.5\n",
        "R_factor = 0.5\n",
        "S_factor = 0.5\n"
      ],
      "metadata": {
        "id": "j4v_PomPLUcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CONFIGURE TOOLS"
      ],
      "metadata": {
        "id": "s2db-k-U6qNk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idaGUgnAUmab"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import ipywidgets as widgets # Import ipywidgets to access the selector\n",
        "from IPython.display import display, Markdown\n",
        "from datetime import datetime\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Define the report_folder_name using repository_name and analysis_run_date\n",
        "# repository_name is from the 'which-repo' cell (borUqKOx6vVf)\n",
        "# analysis_run_date is from the 'Get repository info' cell (-zplV57Ea4LY)\n",
        "\n",
        "# Ensure analysis_run_date is available (defined in -zplV57Ea4LY)\n",
        "if 'analysis_run_date' not in globals():\n",
        "    # Fallback if analysis_run_date hasn't been set yet\n",
        "    current_date_str = datetime.now().strftime('%Y-%m-%d')\n",
        "else:\n",
        "    # Use the date from the analysis, formatted for folder names\n",
        "    # analysis_run_date is already a string '%Y-%m-%d %H:%M:%S', reformat for folder name\n",
        "    current_date_obj = datetime.strptime(analysis_run_date, '%Y-%m-%d %H:%M:%S')\n",
        "    current_date_str = current_date_obj.strftime('%Y-%m-%d')\n",
        "\n",
        "report_folder_name = f\"{repository_name}-{current_date_str}\"\n",
        "\n",
        "# Define the output folder path using report_path (from 'report' cell) and report_folder_name\n",
        "# Ensure report_path is defined in the 'report' cell (OnyMCQQSVi00)\n",
        "output_folder = os.path.join('/content/gdrive', report_path, report_folder_name)\n",
        "\n",
        "# Create the folder if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "print(f\"Output folder '{output_folder}' ensured to exist.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b498cb1c"
      },
      "source": [
        "# cellname : prepare-tools\n",
        "\n",
        "!pip --quiet install PyGithub\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a-Sh5RzUtFc"
      },
      "source": [
        "import plotly.io as pio\n",
        "import os\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "def save_plotly_figure_as_html(fig, filename):\n",
        "    \"\"\"\n",
        "    Saves a Plotly figure as an interactive HTML file in the designated output folder.\n",
        "\n",
        "    Args:\n",
        "        fig (plotly.graph_objects.Figure): The Plotly figure object to save.\n",
        "        filename (str): The desired filename (e.g., 'my_plot.html').\n",
        "    \"\"\"\n",
        "    global output_folder\n",
        "\n",
        "    # Ensure filename has .html extension\n",
        "    if not filename.lower().endswith('.html'):\n",
        "        filename = os.path.splitext(filename)[0] + '.html'\n",
        "\n",
        "    full_path = os.path.join(output_folder, filename)\n",
        "    pio.write_html(fig, full_path, auto_open=False) # auto_open=False to prevent browser from opening\n",
        "    print(f\"Figure saved to: {full_path}\")\n",
        "\n",
        "\n",
        "def save_fig(fig, filename):\n",
        "    \"\"\"\n",
        "    Conditionally saves a Plotly figure as an interactive HTML file\n",
        "    if report generation is enabled via the 'generate_report_value' variable.\n",
        "\n",
        "    Args:\n",
        "        fig (plotly.graph_objects.Figure): The Plotly figure object to save.\n",
        "        filename (str): The desired filename (e.g., 'my_plot.html').\n",
        "    \"\"\"\n",
        "    # Access the global variable 'generate_report_value' directly\n",
        "    if 'generate_report_value' in globals() and generate_report_value.lower() == 'y':\n",
        "        save_plotly_figure_as_html(fig, filename)\n",
        "    else:\n",
        "        print(f\"Report generation is not enabled. Skipping saving '{filename}'.\")\n",
        "\n",
        "print(\"Function 'save_fig' defined.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47bf3e6b"
      },
      "source": [
        "from datetime import timedelta\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Calculate the corresponding timedelta from num_weeks (defined in the 'period' cell)\n",
        "selected_timedelta = timedelta(weeks=num_weeks)\n",
        "\n",
        "# Create a string representation for the report\n",
        "selected_period_str = f'{num_weeks} week' if num_weeks == 1 else f'{num_weeks} weeks'\n",
        "\n",
        "# Display the selected period for confirmation\n",
        "display(Markdown(f'**Analysis Period: {selected_period_str}**'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83aa36a9"
      },
      "source": [
        "# cellname : token\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from github import Github\n",
        "\n",
        "# Retrieve the GitHub token from Colab secrets\n",
        "github_token = userdata.get('GITHUB_TOKEN')\n",
        "\n",
        "if github_token is None:\n",
        "    print(\"GitHub token not found. Please add it to Colab secrets with the name 'GITHUB_TOKEN'.\")\n",
        "else:\n",
        "    # Authenticate with the GitHub API\n",
        "    g = Github(github_token)\n",
        "    print(\"Successfully authenticated with GitHub API.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FETCH DEVELOPERS"
      ],
      "metadata": {
        "id": "uR0938TCI1RY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get repository info"
      ],
      "metadata": {
        "id": "HnFYV5TsfWld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    repo = g.get_user(owner).get_repo(repository_name)\n",
        "    print(f\"Repository Name: {repo.name}\")\n",
        "    print(f\"Repository Description: {repo.description}\")\n",
        "    print(f\"Repository URL: {repo.html_url}\")\n",
        "    print(f\"Stars: {repo.stargazers_count}\")\n",
        "    print(f\"Forks: {repo.forks_count}\")\n",
        "    print(f\"Created At: {repo.created_at}\")\n",
        "    print(f\"Last Updated At: {repo.updated_at}\")\n",
        "\n",
        "    # Capture and print the current analysis run date\n",
        "    from datetime import datetime # Ensure datetime is imported\n",
        "    analysis_run_date = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "    print(f\"Analysis Run Date: {analysis_run_date}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error fetching repository information: {e}\")\n",
        "    # If you see an error here AFTER replacing the owner and repository_name,\n",
        "    # please copy and paste the full error message so I can assist you."
      ],
      "metadata": {
        "id": "-zplV57Ea4LY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07e973f9"
      },
      "source": [
        "## Get contributors\n",
        "All people that contributed to the project, even if not with repository access (i.e. including external contributors)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eab2221"
      },
      "source": [
        "raw_contributors = repo.get_contributors() # Fetch all contributors first\n",
        "\n",
        "filtered_contributors = []\n",
        "bot_logins_to_exclude = ['Copilot'] # Explicitly exclude Copilot as it caused 404 in previous cells\n",
        "\n",
        "for contributor in raw_contributors:\n",
        "    # Check if contributor is a bot based on type or common naming conventions\n",
        "    is_bot = (\n",
        "        contributor.type == 'Bot' or\n",
        "        contributor.login.endswith('[bot]') or\n",
        "        contributor.login in bot_logins_to_exclude\n",
        "    )\n",
        "\n",
        "    if not is_bot:\n",
        "        filtered_contributors.append(contributor)\n",
        "\n",
        "all_contributors = filtered_contributors # Update all_contributors with the filtered list\n",
        "\n",
        "print(f\"Found {len(all_contributors)} non-bot contributors.\")\n",
        "\n",
        "# Display the login, name, and number of contributions for the first few non-bot contributors\n",
        "print(\"\\nFirst 5 non-bot contributors:\")\n",
        "for i, contributor in enumerate(all_contributors):\n",
        "    if i >= 5:\n",
        "        break\n",
        "    # Get contributor name, handling cases where it might be None\n",
        "    contributor_name = contributor.name if contributor.name else \"N/A\"\n",
        "    # Use f-string formatting to align output\n",
        "    print(f\"- {contributor.login:<20}  {contributor_name:<30}    Contributions: {contributor.contributions}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d134c9a"
      },
      "source": [
        "## Get collaborators\n",
        "This is a list of everyone with access to the repostory, even those who never effectively contributed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5e2d235"
      },
      "source": [
        "collaborators = repo.get_collaborators()\n",
        "\n",
        "print(f\"Found {collaborators.totalCount} collaborators with access to the repository.\")\n",
        "\n",
        "print(\"\\nFirst 5 collaborators:\")\n",
        "for i, collaborator in enumerate(collaborators):\n",
        "    if i >= 5:\n",
        "        break\n",
        "    # Get collaborator name, handling cases where it might be None\n",
        "    collaborator_name = collaborator.name if collaborator.name else \"N/A\"\n",
        "\n",
        "    permissions_list = []\n",
        "    if collaborator.permissions.admin: permissions_list.append('admin')\n",
        "    if collaborator.permissions.push: permissions_list.append('push')\n",
        "    if collaborator.permissions.pull: permissions_list.append('pull')\n",
        "\n",
        "    print(f\"- {collaborator.login:<20}  Name: {collaborator_name:<30}  Permissions: {', '.join(permissions_list) if permissions_list else 'None'}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Consolidate developers\n",
        "Create a dataframe with all collaborators (people with repository access), plus anyone else that has contributed (external contributors)."
      ],
      "metadata": {
        "id": "ni91UrakXzTx"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0ac2a4c"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# --- 1. Prepare base information for all unique individuals (collaborators + external contributors) ---\n",
        "\n",
        "# Dictionary to store basic details for each unique person\n",
        "# Key: login (str), Value: {'name': str, 'access': str}\n",
        "person_base_info = {}\n",
        "\n",
        "# First, add all collaborators with 'yes' access status\n",
        "# This also populates their names\n",
        "collaborator_logins = set()\n",
        "for coll in collaborators:\n",
        "    collaborator_logins.add(coll.login)\n",
        "    person_base_info[coll.login] = {\n",
        "        'name': coll.name if coll.name else 'N/A',\n",
        "        'access': 'yes'\n",
        "    }\n",
        "\n",
        "# Now, add all_contributors who are NOT collaborators with 'no' access status\n",
        "for contr in all_contributors:\n",
        "    if contr.login not in person_base_info:\n",
        "        # This person is a contributor but not a direct collaborator\n",
        "        person_base_info[contr.login] = {\n",
        "            'name': contr.name if contr.name else 'N/A',\n",
        "            'access': 'no'\n",
        "        }\n",
        "    else:\n",
        "        # If a person is both a contributor and a collaborator, ensure their name is captured\n",
        "        # in case the contributor object had a better name than the collaborator object\n",
        "        if person_base_info[contr.login]['name'] == 'N/A' and contr.name:\n",
        "            person_base_info[contr.login]['name'] = contr.name\n",
        "\n",
        "# Convert this base info to a DataFrame\n",
        "df_people = pd.DataFrame.from_dict(person_base_info, orient='index')\n",
        "df_people.index.name = 'github_login'\n",
        "df_people = df_people.reset_index()\n",
        "\n",
        "print(\"Unified DataFrame of Collaborators and External Contributors:\")\n",
        "display(df_people.head())\n",
        "\n",
        "#print(\"\\nDataFrame Info:\")\n",
        "#df_people.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FETCH EVENTS"
      ],
      "metadata": {
        "id": "BvkieIyoJLuK"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eb05bee"
      },
      "source": [
        "from datetime import timedelta\n",
        "\n",
        "# selected_timedelta is now calculated directly in the 'period' cell.\n",
        "# This cell now just confirms the value.\n",
        "\n",
        "print(f\"Corresponding timedelta for analysis: {selected_timedelta}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaef677d"
      },
      "source": [
        "num_core_devs = df_people[df_people['access'] == 'yes'].shape[0]\n",
        "num_externals = df_people[df_people['access'] == 'no'].shape[0]\n",
        "\n",
        "print(f\"* Number of collaborators (core devs): {num_core_devs}\")\n",
        "print(f\"* Number of contributors without repo access (externals): {num_externals}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Issues\n",
        "\n"
      ],
      "metadata": {
        "id": "6jRBVB1BfafK"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd46d806"
      },
      "source": [
        "\n",
        "## Get issues open\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from github import Github\n",
        "from datetime import datetime, timedelta, timezone\n",
        "import pandas as pd\n",
        "\n",
        "# Calculate the start date based on the selected_timedelta\n",
        "# Ensure selected_timedelta is available from previous cells\n",
        "start_date = datetime.now(timezone.utc) - selected_timedelta\n",
        "\n",
        "# Dictionary to store issues opened count per user\n",
        "issues_opened_count = {}\n",
        "\n",
        "# Fetch all issues since the start_date. This fetches issues CREATED or UPDATED since start_date.\n",
        "issues = repo.get_issues(state='all', since=start_date)\n",
        "\n",
        "for issue in issues:\n",
        "    # Only count issues that were CREATED within the selected period\n",
        "    if issue.user and issue.created_at >= start_date:\n",
        "        login = issue.user.login\n",
        "        issues_opened_count[login] = issues_opened_count.get(login, 0) + 1\n",
        "\n",
        "# Convert the dictionary to a pandas Series for merging\n",
        "issues_opened_series = pd.Series(issues_opened_count, name='issues_opened_count')\n",
        "\n",
        "# --- Fix for KeyError: Drop existing 'issues_opened_count' related columns before merging ---\n",
        "columns_to_drop = [col for col in df_people.columns if col.startswith('issues_opened_count')]\n",
        "if columns_to_drop:\n",
        "    df_people = df_people.drop(columns=columns_to_drop)\n",
        "\n",
        "df_people = df_people.set_index('github_login')\n",
        "df_people = df_people.merge(issues_opened_series, left_index=True, right_index=True, how='left')\n",
        "df_people = df_people.reset_index()\n",
        "\n",
        "# Fill NaN values with 0 for users who didn't open any issues in the period\n",
        "df_people['issues_opened_count'] = df_people['issues_opened_count'].fillna(0).astype(int)\n",
        "\n",
        "print(\"df_people DataFrame with 'issues_opened_count' column:\")\n",
        "display(df_people.head())\n",
        "\n",
        "print(\"\\nTop 4 people with most issues opened:\")\n",
        "top_issues_openers = df_people.sort_values(by='issues_opened_count', ascending=False).head(4)\n",
        "for index, row in top_issues_openers.iterrows():\n",
        "    print(f\"- {row['github_login']} ({row['name'] if row['name'] != 'N/A' else 'Name not available'}): {row['issues_opened_count']} issues opened\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57d02691"
      },
      "source": [
        "\n",
        "## Get issues reopened\n",
        "\n",
        "from datetime import datetime, timezone\n",
        "import pandas as pd\n",
        "\n",
        "# Ensure selected_timedelta is available from previous cells\n",
        "start_date = datetime.now(timezone.utc) - selected_timedelta\n",
        "\n",
        "# Dictionary to store issues reopened count per user\n",
        "issues_reopened_count = {}\n",
        "\n",
        "# Fetch all issues that were created or updated since the start_date\n",
        "# This gives us a pool of issues that might have been reopened in the period\n",
        "issues_in_period = repo.get_issues(state='all', since=start_date)\n",
        "\n",
        "for issue in issues_in_period:\n",
        "    try:\n",
        "        # Get events for this specific issue (timeline events)\n",
        "        issue_timeline_events = issue.get_events()\n",
        "        for event in issue_timeline_events:\n",
        "            # Check if the event is a 'reopened' event, happened in the period, and has an actor\n",
        "            if event.event == 'reopened' and event.created_at >= start_date and event.actor:\n",
        "                login = event.actor.login\n",
        "                issues_reopened_count[login] = issues_reopened_count.get(login, 0) + 1\n",
        "    except Exception as e:\n",
        "        # Handle potential errors if issue events cannot be fetched (e.g., rate limits, deleted events)\n",
        "        print(f\"Warning: Could not fetch events for issue #{issue.number}: {e}\")\n",
        "\n",
        "# Convert the dictionary to a pandas Series for merging\n",
        "issues_reopened_series = pd.Series(issues_reopened_count, name='issues_reopened_count')\n",
        "\n",
        "# Merge the counts into df_people\n",
        "df_people = df_people.set_index('github_login')\n",
        "df_people = df_people.merge(issues_reopened_series, left_index=True, right_index=True, how='left')\n",
        "df_people = df_people.reset_index()\n",
        "\n",
        "# Fill NaN values with 0 for users who didn't reopen any issues in the period\n",
        "df_people['issues_reopened_count'] = df_people['issues_reopened_count'].fillna(0).astype(int)\n",
        "\n",
        "print(\"df_people DataFrame with 'issues_reopened_count' column:\")\n",
        "display(df_people.head())\n",
        "\n",
        "print(\"\\nTop 4 people with most issues reopened:\")\n",
        "top_reopeners = df_people.sort_values(by='issues_reopened_count', ascending=False).head(4)\n",
        "for index, row in top_reopeners.iterrows():\n",
        "    print(f\"- {row['github_login']} ({row['name'] if row['name'] != 'N/A' else 'Name not available'}): {row['issues_reopened_count']} issues reopened\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comments\n",
        "\n",
        "PR are treated as issues with code."
      ],
      "metadata": {
        "id": "HiYtDtHwgUYV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a826c89"
      },
      "source": [
        "from datetime import datetime, timezone\n",
        "import pandas as pd\n",
        "\n",
        "# Ensure selected_timedelta is available from previous cells\n",
        "start_date = datetime.now(timezone.utc) - selected_timedelta\n",
        "\n",
        "# Dictionary to store IssueCommentEvent counts per user\n",
        "issue_comment_event_counts = {}\n",
        "\n",
        "# --- Process Issue Comments ---\n",
        "# Fetch all issues since the start_date (this method supports 'since')\n",
        "issues_in_period = repo.get_issues(state='all', since=start_date)\n",
        "\n",
        "for issue in issues_in_period:\n",
        "    # Fetch comments for each issue\n",
        "    comments = issue.get_comments()\n",
        "    for comment in comments:\n",
        "        # Ensure the comment itself was created within the period and has a user\n",
        "        if comment.user and comment.created_at >= start_date:\n",
        "            login = comment.user.login\n",
        "            issue_comment_event_counts[login] = issue_comment_event_counts.get(login, 0) + 1\n",
        "\n",
        "# --- Process Pull Request Comments (which are also IssueCommentEvent conceptually) ---\n",
        "# Fetch all pull requests (this method does NOT support 'since')\n",
        "pulls_in_period = repo.get_pulls(state='all')\n",
        "\n",
        "for pull in pulls_in_period:\n",
        "    # Fetch comments for each pull request\n",
        "    comments = pull.get_comments()\n",
        "    for comment in comments:\n",
        "        # Ensure the comment itself was created within the period and has a user\n",
        "        if comment.user and comment.created_at >= start_date:\n",
        "            login = comment.user.login\n",
        "            issue_comment_event_counts[login] = issue_comment_event_counts.get(login, 0) + 1\n",
        "\n",
        "# Convert the dictionary to a pandas Series for merging\n",
        "issue_comment_event_series = pd.Series(issue_comment_event_counts, name='issue_comment_event_count')\n",
        "\n",
        "# Merge the counts into df_people\n",
        "df_people = df_people.set_index('github_login')\n",
        "df_people = df_people.merge(issue_comment_event_series, left_index=True, right_index=True, how='left')\n",
        "df_people = df_people.reset_index()\n",
        "\n",
        "# Fill NaN values with 0 for users who didn't perform any IssueCommentEvent in the period\n",
        "df_people['issue_comment_event_count'] = df_people['issue_comment_event_count'].fillna(0).astype(int)\n",
        "\n",
        "print(\"df_people DataFrame with 'issue_comment_event_count' column:\")\n",
        "display(df_people.head())\n",
        "\n",
        "print(\"\\nTop 4 people with most IssueCommentEvents:\")\n",
        "top_commenters = df_people.sort_values(by='issue_comment_event_count', ascending=False).head(4)\n",
        "for index, row in top_commenters.iterrows():\n",
        "    print(f\"- {row['github_login']} ({row['name'] if row['name'] != 'N/A' else 'Name not available'}): {row['issue_comment_event_count']} IssueCommentEvents\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pull requests"
      ],
      "metadata": {
        "id": "QlBI3kXmjMKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, timezone\n",
        "import pandas as pd\n",
        "\n",
        "# Ensure selected_timedelta is available from previous cells\n",
        "start_date = datetime.now(timezone.utc) - selected_timedelta\n",
        "\n",
        "# Dictionary to store pull requests opened count per user\n",
        "pull_requests_opened_count = {}\n",
        "# Dictionary to store pull requests merged count per user\n",
        "pull_requests_merged_count = {}\n",
        "# Dictionary to store pull requests closed (including merged) count per user\n",
        "pull_requests_closed_count = {}\n",
        "\n",
        "# Fetch all pull requests (this method does NOT support 'since' for 'all' state directly, but can filter later)\n",
        "# It's generally better to iterate through all and filter by date.\n",
        "all_pulls = repo.get_pulls(state='all')\n",
        "\n",
        "for pull in all_pulls:\n",
        "    # Only count pull requests that were CREATED within the selected period\n",
        "    if pull.user and pull.created_at >= start_date:\n",
        "        login = pull.user.login\n",
        "        pull_requests_opened_count[login] = pull_requests_opened_count.get(login, 0) + 1\n",
        "\n",
        "    # Count pull requests that were MERGED within the selected period\n",
        "    if pull.merged and pull.merged_at and pull.merged_at >= start_date:\n",
        "        if pull.merged_by:\n",
        "            login = pull.merged_by.login\n",
        "            pull_requests_merged_count[login] = pull_requests_merged_count.get(login, 0) + 1\n",
        "\n",
        "    # Count pull requests that were CLOSED (either merged or closed without merging) within the selected period\n",
        "    # Note: 'closed_at' is typically populated for both merged and explicitly closed PRs.\n",
        "    # We attribute the closure to the user who opened the PR for PI calculation.\n",
        "    if pull.user and pull.state == 'closed' and pull.closed_at and pull.closed_at >= start_date:\n",
        "        login = pull.user.login # User who created the PR\n",
        "        pull_requests_closed_count[login] = pull_requests_closed_count.get(login, 0) + 1\n",
        "\n",
        "# Convert the dictionaries to pandas Series for merging\n",
        "pull_requests_opened_series = pd.Series(pull_requests_opened_count, name='pull_requests_opened_count')\n",
        "pull_requests_merged_series = pd.Series(pull_requests_merged_count, name='pull_requests_merged_count')\n",
        "pull_requests_closed_series = pd.Series(pull_requests_closed_count, name='pull_requests_closed_count')\n",
        "\n",
        "\n",
        "# --- Drop existing 'pull_requests_opened_count', 'pull_requests_merged_count', 'pull_requests_closed_count' related columns before merging ---\n",
        "columns_to_drop_opened = [col for col in df_people.columns if col.startswith('pull_requests_opened_count')]\n",
        "if columns_to_drop_opened:\n",
        "    df_people = df_people.drop(columns=columns_to_drop_opened)\n",
        "\n",
        "columns_to_drop_merged = [col for col in df_people.columns if col.startswith('pull_requests_merged_count')]\n",
        "if columns_to_drop_merged:\n",
        "    df_people = df_people.drop(columns=columns_to_drop_merged)\n",
        "\n",
        "columns_to_drop_closed = [col for col in df_people.columns if col.startswith('pull_requests_closed_count')]\n",
        "if columns_to_drop_closed:\n",
        "    df_people = df_people.drop(columns=columns_to_drop_closed)\n",
        "\n",
        "\n",
        "df_people = df_people.set_index('github_login')\n",
        "\n",
        "# Merge counts\n",
        "df_people = df_people.merge(pull_requests_opened_series, left_index=True, right_index=True, how='left')\n",
        "df_people = df_people.merge(pull_requests_merged_series, left_index=True, right_index=True, how='left')\n",
        "df_people = df_people.merge(pull_requests_closed_series, left_index=True, right_index=True, how='left')\n",
        "\n",
        "df_people = df_people.reset_index()\n",
        "\n",
        "# Fill NaN values with 0\n",
        "df_people['pull_requests_opened_count'] = df_people['pull_requests_opened_count'].fillna(0).astype(int)\n",
        "df_people['pull_requests_merged_count'] = df_people['pull_requests_merged_count'].fillna(0).astype(int)\n",
        "df_people['pull_requests_closed_count'] = df_people['pull_requests_closed_count'].fillna(0).astype(int)\n",
        "\n",
        "print(\"df_people DataFrame with PR counts:\")\n",
        "display(df_people.head())\n",
        "\n",
        "print(\"\\nTop 4 people with most Pull Requests opened:\")\n",
        "top_pr_openers = df_people.sort_values(by='pull_requests_opened_count', ascending=False).head(4)\n",
        "for index, row in top_pr_openers.iterrows():\n",
        "    print(f\"- {row['github_login']} ({row['name'] if row['name'] != 'N/A' else 'Name not available'}): {row['pull_requests_opened_count']} PRs opened\")\n",
        "\n",
        "print(\"\\nTop 4 people with most Pull Requests merged:\")\n",
        "top_pr_mergers = df_people.sort_values(by='pull_requests_merged_count', ascending=False).head(4)\n",
        "for index, row in top_pr_mergers.iterrows():\n",
        "    print(f\"- {row['github_login']} ({row['name'] if row['name'] != 'N/A' else 'Name not available'}): {row['pull_requests_merged_count']} PRs merged\")\n",
        "\n",
        "print(\"\\nTop 4 people with most Pull Requests closed:\")\n",
        "top_pr_closed = df_people.sort_values(by='pull_requests_closed_count', ascending=False).head(4)\n",
        "for index, row in top_pr_closed.iterrows():\n",
        "    print(f\"- {row['github_login']} ({row['name'] if row['name'] != 'N/A' else 'Name not available'}): {row['pull_requests_closed_count']} PRs closed\")"
      ],
      "metadata": {
        "id": "oLvGLSeBjWaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code changes"
      ],
      "metadata": {
        "id": "k7PpvKkpqcca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, timezone\n",
        "import pandas as pd\n",
        "\n",
        "# Ensure selected_timedelta is available from previous cells\n",
        "start_date = datetime.now(timezone.utc) - selected_timedelta\n",
        "\n",
        "# Dictionaries to store additions and deletions per user\n",
        "user_additions = {}\n",
        "user_deletions = {}\n",
        "\n",
        "print(f\"Fetching code changes from merged and currently open Pull Requests since {start_date}...\")\n",
        "\n",
        "# Fetch all pull requests (open, closed, and all states to check merged status)\n",
        "all_pulls = repo.get_pulls(state='all')\n",
        "\n",
        "for pull in all_pulls:\n",
        "    process_pull = False\n",
        "    # Condition 1: PR was merged within the period\n",
        "    if pull.merged and pull.merged_at and pull.merged_at >= start_date:\n",
        "        process_pull = True\n",
        "    # Condition 2: PR is currently open\n",
        "    elif pull.state == 'open':\n",
        "        process_pull = True\n",
        "\n",
        "    if process_pull:\n",
        "        # Iterate through the commits of the relevant PR\n",
        "        try:\n",
        "            pr_commits = pull.get_commits()\n",
        "            for commit in pr_commits:\n",
        "                # Check if the commit's author exists\n",
        "                if commit.author and commit.author.login:\n",
        "                    login = commit.author.login\n",
        "                    try:\n",
        "                        full_commit = repo.get_commit(commit.sha)\n",
        "                        if full_commit.stats:\n",
        "                            user_additions[login] = user_additions.get(login, 0) + full_commit.stats.additions\n",
        "                            user_deletions[login] = user_deletions.get(login, 0) + full_commit.stats.deletions\n",
        "                    except Exception as e:\n",
        "                        print(f\"Warning: Could not fetch stats for commit {commit.sha} in PR #{pull.number} by {login}: {e}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not fetch commits for PR #{pull.number}: {e}\")\n",
        "\n",
        "# Convert dictionaries to pandas Series\n",
        "additions_series = pd.Series(user_additions, name='total_additions')\n",
        "deletions_series = pd.Series(user_deletions, name='total_deletions')\n",
        "\n",
        "# --- Drop existing columns before merging ---\n",
        "# This prevents duplicate columns if the cell is run multiple times\n",
        "columns_to_drop_add = [col for col in df_people.columns if col.startswith('total_additions')]\n",
        "if columns_to_drop_add:\n",
        "    df_people = df_people.drop(columns=columns_to_drop_add)\n",
        "\n",
        "columns_to_drop_del = [col for col in df_people.columns if col.startswith('total_deletions')]\n",
        "if columns_to_drop_del:\n",
        "    df_people = df_people.drop(columns=columns_to_drop_del)\n",
        "\n",
        "df_people = df_people.set_index('github_login')\n",
        "\n",
        "# Merge additions and deletions into df_people\n",
        "df_people = df_people.merge(additions_series, left_index=True, right_index=True, how='left')\n",
        "df_people = df_people.merge(deletions_series, left_index=True, right_index=True, how='left')\n",
        "\n",
        "df_people = df_people.reset_index()\n",
        "\n",
        "# Fill NaN values with 0 for users who had no additions or deletions in the period\n",
        "df_people['total_additions'] = df_people['total_additions'].fillna(0).astype(int)\n",
        "df_people['total_deletions'] = df_people['total_deletions'].fillna(0).astype(int)\n",
        "\n",
        "print(\"\\ndf_people DataFrame with 'total_additions' and 'total_deletions' columns:\")\n",
        "display(df_people.head())\n",
        "\n",
        "print(\"\\nTop 4 people with most additions:\")\n",
        "top_adders = df_people.sort_values(by='total_additions', ascending=False).head(4)\n",
        "for index, row in top_adders.iterrows():\n",
        "    print(f\"- {row['github_login']} ({row['name'] if row['name'] != 'N/A' else 'Name not available'}): {row['total_additions']} additions\")\n",
        "\n",
        "print(\"\\nTop 4 people with most deletions:\")\n",
        "top_deleters = df_people.sort_values(by='total_deletions', ascending=False).head(4)\n",
        "for index, row in top_deleters.iterrows():\n",
        "    print(f\"- {row['github_login']} ({row['name'] if row['name'] != 'N/A' else 'Name not available'}): {row['total_deletions']} deletions\")"
      ],
      "metadata": {
        "id": "S4jKZz3Lqd-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cellname : fix-count-scales\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 2. Define a list named other_event_cols\n",
        "other_event_cols = [\n",
        "    'issues_opened_count',\n",
        "    'issues_reopened_count',\n",
        "    'issue_comment_event_count',\n",
        "    'pull_requests_opened_count',\n",
        "    'pull_requests_merged_count'\n",
        "]\n",
        "\n",
        "# Ensure all columns exist, filter out non-existent ones if any\n",
        "existing_other_event_cols = [col for col in other_event_cols if col in df_people.columns]\n",
        "\n",
        "# 3. Calculate max_other_event_count\n",
        "if existing_other_event_cols:\n",
        "    max_other_event_count = df_people[existing_other_event_cols].max().max()\n",
        "else:\n",
        "    max_other_event_count = 0\n",
        "\n",
        "# Avoid division by zero if no other events\n",
        "if max_other_event_count == 0:\n",
        "    max_other_event_count = 1\n",
        "\n",
        "# 4. Calculate max_total_additions and max_total_deletions\n",
        "max_total_additions = df_people['total_additions'].max()\n",
        "max_total_deletions = df_people['total_deletions'].max()\n",
        "\n",
        "# Determine max_code_change as the maximum value between max_total_additions and max_total_deletions\n",
        "max_code_change = max(max_total_additions, max_total_deletions)\n",
        "\n",
        "# Calculate the scaling_ratio by dividing max_code_change by max_other_event_count\n",
        "# Handle the case where max_other_event_count is zero to avoid division errors.\n",
        "scaling_ratio = max_code_change / max_other_event_count if max_other_event_count > 0 else 0\n",
        "\n",
        "# Based on scaling_ratio, determine the chosen_factor:\n",
        "chosen_factor = 1 # Default value\n",
        "if max_code_change == 0: # If there are no code changes, factor is 1\n",
        "    chosen_factor = 1\n",
        "elif scaling_ratio <= 1:\n",
        "    chosen_factor = 1\n",
        "elif 1 < scaling_ratio <= 10:\n",
        "    chosen_factor = 10\n",
        "elif scaling_ratio > 10 and scaling_ratio <= 100:\n",
        "    chosen_factor = int(np.ceil(scaling_ratio / 10)) * 10\n",
        "elif scaling_ratio > 100:\n",
        "    chosen_factor = int(np.ceil(scaling_ratio / 100)) * 100\n",
        "\n",
        "# Create a scaled_label_suffix string\n",
        "if chosen_factor == 1:\n",
        "    scaled_label_suffix = ''\n",
        "else:\n",
        "    scaled_label_suffix = f' (x{chosen_factor})'\n",
        "\n",
        "# 5. Initialize new columns (or overwrite if they exist)\n",
        "df_people['scaled_additions'] = 0.0\n",
        "df_people['scaled_deletions'] = 0.0\n",
        "\n",
        "# Update the scaled_additions column in df_people\n",
        "df_people['scaled_additions'] = df_people['total_additions'] / chosen_factor\n",
        "\n",
        "# Update the scaled_deletions column in df_people\n",
        "df_people['scaled_deletions'] = df_people['total_deletions'] / chosen_factor\n",
        "\n",
        "# 8. Print the calculated values\n",
        "print(f\"Maximum count of other event types (for scaling): {max_other_event_count}\")\n",
        "print(f\"Maximum total additions: {max_total_additions}\")\n",
        "print(f\"Maximum total deletions: {max_total_deletions}\")\n",
        "print(f\"Maximum code change (additions or deletions): {max_code_change}\")\n",
        "if max_code_change > 0 and max_other_event_count > 0:\n",
        "    print(f\"Scaling ratio (max_code_change / max_other_event_count): {scaling_ratio:.4f}\")\n",
        "print(f\"Chosen factor for scaling code changes: {chosen_factor}\")\n",
        "print(f\"Scaled label suffix: '{scaled_label_suffix}'\")\n",
        "\n",
        "# 9. Display the head of the df_people DataFrame\n",
        "print(\"\\ndf_people DataFrame with scaled additions and deletions:\")\n",
        "display(df_people[['github_login', 'name', 'total_additions', 'scaled_additions', 'total_deletions', 'scaled_deletions']].head())\n",
        "\n",
        "# 10. Print top 4 contributors by scaled_additions\n",
        "print(\"\\nTop 4 people by scaled additions:\")\n",
        "top_scaled_adders = df_people.sort_values(by='scaled_additions', ascending=False).head(4)\n",
        "for index, row in top_scaled_adders.iterrows():\n",
        "    print(f\"- {row['github_login']} ({row['name'] if row['name'] != 'N/A' else 'Name not available'}): {row['scaled_additions']:.2f} scaled additions\")\n",
        "\n",
        "# 11. Print top 4 contributors by scaled_deletions\n",
        "print(\"\\nTop 4 people by scaled deletions:\")\n",
        "top_scaled_deleters = df_people.sort_values(by='scaled_deletions', ascending=False).head(4)\n",
        "for index, row in top_scaled_deleters.iterrows():\n",
        "    print(f\"- {row['github_login']} ({row['name'] if row['name'] != 'N/A' else 'Name not available'}): {row['scaled_deletions']:.2f} scaled deletions\")"
      ],
      "metadata": {
        "id": "j-NJ5SHRtkyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PROJECT OVERVIEW"
      ],
      "metadata": {
        "id": "kJyZNQbQyI_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cellname : time-plot"
      ],
      "metadata": {
        "id": "GWv7aCkB9y7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Events (totals)\n",
        "\n",
        "* Show all events in the period (ommit devs that haven't generated events)"
      ],
      "metadata": {
        "id": "-JDHRPapvrUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cellname : show-all-events\n",
        "\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "# Diagnostic: Print all columns in df_people before processing for the plot\n",
        "print(\"Current columns in df_people before plotting:\")\n",
        "print(df_people.columns)\n",
        "\n",
        "# Define the columns that represent events, NOW USING SCALED ADDITIONS AND DELETIONS\n",
        "event_columns = [\n",
        "    'issues_opened_count',\n",
        "    'issues_reopened_count',\n",
        "    'issue_comment_event_count',\n",
        "    'pull_requests_opened_count',\n",
        "    'pull_requests_merged_count',\n",
        "    'scaled_additions',  # Use scaled additions\n",
        "    'scaled_deletions'   # Use scaled deletions\n",
        "]\n",
        "\n",
        "# Ensure all event columns exist in df_people\n",
        "existing_event_columns = [col for col in event_columns if col in df_people.columns]\n",
        "\n",
        "# Filter out developers with no activity in any of the tracked events for cleaner visualization\n",
        "df_plot = df_people[df_people[existing_event_columns].sum(axis=1) > 0].copy()\n",
        "\n",
        "# Rename columns for better plot labels (optional, but good practice)\n",
        "df_plot = df_plot.rename(columns={\n",
        "    'issues_opened_count': 'Issues Opened',\n",
        "    'issues_reopened_count': 'Issues Reopened',\n",
        "    'issue_comment_event_count': 'Comments (Issues/PRs)',\n",
        "    'pull_requests_opened_count': 'PRs Opened',\n",
        "    'pull_requests_merged_count': 'PRs Merged',\n",
        "    'scaled_additions': f'Lines Added{scaled_label_suffix}', # Updated label with suffix\n",
        "    'scaled_deletions': f'Lines Removed{scaled_label_suffix}' # Updated label with suffix\n",
        "})\n",
        "\n",
        "# Melt the DataFrame to a long format suitable for stacked bar charts\n",
        "# We use 'github_login' as the id_vars because we want one bar per developer\n",
        "df_melted = df_plot.melt(id_vars=['github_login', 'name'], value_vars=[col for col in df_plot.columns if col in [f'Lines Added{scaled_label_suffix}', f'Lines Removed{scaled_label_suffix}', 'Issues Opened', 'Issues Reopened', 'Comments (Issues/PRs)', 'PRs Opened', 'PRs Merged']],\n",
        "                         var_name='Event Type', value_name='Count')\n",
        "\n",
        "# Create the stacked bar chart using Plotly Express\n",
        "fig = px.bar(df_melted,\n",
        "             x='github_login',\n",
        "             y='Count',\n",
        "             color='Event Type',\n",
        "             title=f'Events per Contributor', # Updated title\n",
        "             labels={'github_login': 'Contributor', 'Count': 'Event Count'},\n",
        "             hover_name='name',\n",
        "             hover_data={'Event Type': True, 'Count': ':.2f', 'github_login': False},\n",
        "             text_auto='.2f') # Display text values automatically, formatted to 2 decimal places\n",
        "\n",
        "fig.update_layout(xaxis_title='Contributor',\n",
        "                  yaxis_title='Event Count',\n",
        "                  barmode='stack',\n",
        "                  legend_title='Event Type')\n",
        "\n",
        "# Set text color to white for all traces and position text inside\n",
        "fig.update_traces(textfont_color='white', textposition='inside')\n",
        "\n",
        "# Optional: Adjust x-axis to show only relevant developer names if too many\n",
        "# fig.update_xaxes(tickangle=45, tickfont=dict(size=10))\n",
        "\n",
        "fig.show() # Always show the figure\n",
        "\n",
        "# Save the figure to Google Drive if report generation is enabled\n",
        "save_fig(fig, 'all_primitive_events.html')\n"
      ],
      "metadata": {
        "id": "sls-rXnxrbjh",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agregate events\n",
        "* All events, but aggregating Issues, Commands,PRs and total changes"
      ],
      "metadata": {
        "id": "KblqqbT6v1A4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cellname : all-events-aggregate\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "# Create consolidated event columns\n",
        "df_consolidated = df_people.copy()\n",
        "df_consolidated['Issues'] = df_consolidated['issues_opened_count'] + df_consolidated['issues_reopened_count']\n",
        "df_consolidated['Comments'] = df_consolidated['issue_comment_event_count']\n",
        "df_consolidated['PRs Opened'] = df_consolidated['pull_requests_opened_count']\n",
        "df_consolidated['PRs Merged'] = df_consolidated['pull_requests_merged_count']\n",
        "\n",
        "# Recalculate 'Code Changes' using scaled additions and deletions and include the suffix\n",
        "df_consolidated[f'Code Changes{scaled_label_suffix}'] = df_consolidated['scaled_additions'] + df_consolidated['scaled_deletions']\n",
        "\n",
        "# Define the new consolidated event columns for plotting, now including the scaled suffix\n",
        "consolidated_event_columns = ['Issues', 'Comments', 'PRs Opened', 'PRs Merged', f'Code Changes{scaled_label_suffix}']\n",
        "\n",
        "# Filter out developers with no activity in any of the consolidated events\n",
        "df_plot_consolidated = df_consolidated[df_consolidated[consolidated_event_columns].sum(axis=1) > 0].copy()\n",
        "\n",
        "# Melt the DataFrame to a long format suitable for stacked bar charts\n",
        "df_melted_consolidated = df_plot_consolidated.melt(\n",
        "    id_vars=['github_login', 'name'],\n",
        "    value_vars=consolidated_event_columns,\n",
        "    var_name='Event Type',\n",
        "    value_name='Count'\n",
        ")\n",
        "\n",
        "# Rename 'Issues' to 'Issues Raised' for display in the plot legend\n",
        "df_melted_consolidated['Event Type'] = df_melted_consolidated['Event Type'].replace('Issues', 'Issues Raised')\n",
        "\n",
        "# Add a new column for text display, conditional on Count > 0 and formatted\n",
        "df_melted_consolidated['text_values'] = df_melted_consolidated.apply(lambda row: f\"{row['Count']:.2f}\" if row['Count'] > 0 and row['Event Type'] == f'Code Changes{scaled_label_suffix}' else (f\"{row['Count']:.0f}\" if row['Count'] > 0 else ''), axis=1)\n",
        "\n",
        "\n",
        "# Create the stacked bar chart using Plotly Express\n",
        "fig_consolidated = px.bar(\n",
        "    df_melted_consolidated,\n",
        "    x='github_login',\n",
        "    y='Count',\n",
        "    color='Event Type',\n",
        "    title=f'Categorized event count', # Updated title\n",
        "    labels={'github_login': 'Contributor', 'Count': 'Event Count'},\n",
        "    hover_name='name',\n",
        "    hover_data={'Event Type': True, 'Count': ':.2f', 'github_login': False}, # Format Count to 2 decimal places\n",
        "    text='text_values' # Use the new conditional text column\n",
        ")\n",
        "\n",
        "fig_consolidated.update_layout(\n",
        "    xaxis_title='Contributor',\n",
        "    yaxis_title='Event Count',\n",
        "    barmode='stack',\n",
        "    legend_title='Event Type'\n",
        ")\n",
        "\n",
        "# Adjust x-axis to show labels vertically\n",
        "fig_consolidated.update_xaxes(tickangle=90, tickfont=dict(size=10), showgrid=False)\n",
        "\n",
        "# Revert y-axis grid to default Plotly style, with lines every 5 units\n",
        "fig_consolidated.update_yaxes(showgrid=True, showticklabels=True, dtick=5, gridwidth=1, griddash=None)\n",
        "\n",
        "# Set text color to white for all traces and position text inside\n",
        "fig_consolidated.update_traces(textfont_color='white', textposition='inside')\n",
        "\n",
        "fig_consolidated.show()\n",
        "\n",
        "save_fig(fig_consolidated, 'all_aggregate_events.html')\n"
      ],
      "metadata": {
        "id": "3JF1OLKrv85u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Workload balance (WB) index"
      ],
      "metadata": {
        "id": "bVbGpk-gVHDc"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cc00a1d"
      },
      "source": [
        "# cellname : wbi\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Calculate aggregate PRs opened and closed for the entire project\n",
        "total_prs_opened = df_people['pull_requests_opened_count'].sum()\n",
        "total_prs_closed = df_people['pull_requests_closed_count'].sum()\n",
        "\n",
        "print(f\"Total PRs Opened in the period: {total_prs_opened}\")\n",
        "print(f\"Total PRs Closed in the period: {total_prs_closed}\")\n",
        "\n",
        "# --- Calculate the NEW Aggregate Progress Index (PI) (formerly PR Balance Index) ---\n",
        "# PI = (PRs Closed - PRs Opened) / (PRs Closed + PRs Opened)\n",
        "# Handle case where total_pr_activity is 0 to avoid division by zero\n",
        "total_pr_activity = total_prs_opened + total_prs_closed\n",
        "\n",
        "if total_pr_activity > 0:\n",
        "    # The new PI is the former PR Balance Index\n",
        "    wb_index = (total_prs_closed - total_prs_opened) / total_pr_activity\n",
        "    print(f\"Work Balance (WB): {wb_index:.2f}\\n\")\n",
        "else:\n",
        "    wb_index = 0.0 # Define a default if no PRs were opened and closed\n",
        "    print(\"No PR activity (opened or closed) in the period to calculate the Net Contribution Throughput (NCT).\\n\")\n",
        "\n",
        "# --- Horizontal Bar Chart for Net Contribution Throughput (NCT) ---\n",
        "\n",
        "# Determine marker color dynamically\n",
        "#bar_color_pi = '#AEC6CF'\n",
        "if wb_index < 0:\n",
        "    bar_color_pi = \"#dd5500\"\n",
        "elif wb_index > 0:\n",
        "    bar_color_pi = \"#00aa88\"\n",
        "\n",
        "fig_horizontal_bar = go.Figure()\n",
        "\n",
        "# Add background shapes for the ranges (reverting y0 and y1 for taller colored segments)\n",
        "fig_horizontal_bar.update_layout(\n",
        "    shapes=[\n",
        "        # More vivid Red for [-1, -0.5]\n",
        "        dict(type='rect', xref='x', yref='y', x0=-1, y0=-0.5, x1=-0.5, y1=0.5, fillcolor='#FF6347', opacity=0.3, layer='below', line_width=0),\n",
        "        # More vivid Salmon for [-0.5, 0]\n",
        "        dict(type='rect', xref='x', yref='y', x0=-0.5, y0=-0.5, x1=0, y1=0.5, fillcolor='#FFA07A', opacity=0.3, layer='below', line_width=0),\n",
        "        # More vivid Light Green for [0, 0.5]\n",
        "        dict(type='rect', xref='x', yref='y', x0=0, y0=-0.5, x1=0.5, y1=0.5, fillcolor='#90EE90', opacity=0.3, layer='below', line_width=0),\n",
        "        # More vivid Darker Green for [0.5, 1]\n",
        "        dict(type='rect', xref='x', yref='y', x0=0.5, y0=-0.5, x1=1, y1=0.5, fillcolor='#3CB371', opacity=0.3, layer='below', line_width=0)\n",
        "    ]\n",
        ")\n",
        "\n",
        "fig_horizontal_bar.add_trace(go.Bar(\n",
        "    x=[wb_index],\n",
        "    y=['NCT'],\n",
        "    orientation='h',\n",
        "    base=0,\n",
        "    marker_color=bar_color_pi,\n",
        "    text=f'{wb_index:.2f}',\n",
        "    textposition='inside',\n",
        "    textfont=dict(color='white'),\n",
        "    width=0.4 # Explicitly setting the width (height for horizontal bar) of the blue indicator bar\n",
        "))\n",
        "\n",
        "fig_horizontal_bar.update_layout(\n",
        "    title_text='Workload Balance (WB)', # Updated title\n",
        "    xaxis_range=[-1, 1], # Set x-axis range strictly from -1 to 1\n",
        "    xaxis_title='← Accumulating | Clearing →', # Updated x-axis title\n",
        "    yaxis_visible=False, # Hide y-axis\n",
        "    yaxis_showticklabels=False, # Hide y-axis tick labels\n",
        "    height=150, # Set a reasonable height for the bar chart\n",
        "    width=800, # Set a reasonable width\n",
        "    margin=dict(l=20, r=20, t=50, b=20), # Adjust margins\n",
        "    title_x=0.5 # Center the title\n",
        ")\n",
        "\n",
        "fig_horizontal_bar.show()\n",
        "\n",
        "save_fig(fig_horizontal_bar, 'workload_balance.html')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execution balance index (EBI)"
      ],
      "metadata": {
        "id": "hH3TiyA4TPhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cellname : ebi\n",
        "\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Calculate total issues raised (opened + reopened)\n",
        "total_issues_raised = df_people['issues_opened_count'].sum() + df_people['issues_reopened_count'].sum()\n",
        "\n",
        "# Get total PRs submitted (using 'pull_requests_opened_count' as proxy for submitted)\n",
        "total_prs_submitted = df_people['pull_requests_opened_count'].sum()\n",
        "\n",
        "print(f\"Total Issues Raised in the period: {total_issues_raised}\")\n",
        "print(f\"Total PRs Submitted in the period: {total_prs_submitted}\")\n",
        "\n",
        "# --- Calculate the Submitted Index (SI) ---\n",
        "# SI = (PRs Submitted - Issues Raised) / (PRs Submitted + Issues Raised)\n",
        "# Handle case where total_activity is 0 to avoid division by zero\n",
        "total_activity_for_si = total_prs_submitted + total_issues_raised\n",
        "\n",
        "if total_activity_for_si > 0:\n",
        "    rb_index = (total_prs_submitted - total_issues_raised) / total_activity_for_si\n",
        "    print(f\"Resolution Balance (RB): {rb_index:.2f}\\n\")\n",
        "else:\n",
        "    rb_index = 0.0 # Define a default if no relevant activity\n",
        "    print(\"No PRs submitted or issues raised in the period to calculate the Submitted Index (SI).\\n\")\n",
        "\n",
        "# --- Horizontal Bar Chart for Submitted Index (SI) ---\n",
        "\n",
        "# Determine indicator bar color based on index value, as originally designed\n",
        "if rb_index < 0:\n",
        "    bar_color_si = \"#888800\"\n",
        "elif rb_index > 0:\n",
        "    bar_color_si = \"#0088aa\"\n",
        "else:\n",
        "    bar_color_si = \"#AEC6CF\" # Default grayish-blue if index is 0\n",
        "\n",
        "fig_submitted_bar = go.Figure()\n",
        "\n",
        "# Add background shapes for the ranges (reusing vivid colors from previous notebook state)\n",
        "fig_submitted_bar.update_layout(\n",
        "    shapes=[\n",
        "        # More vivid Red for [-1, -0.5] -> Changed to Yellow\n",
        "        dict(type='rect', xref='x', yref='y', x0=-1, y0=-0.5, x1=-0.5, y1=0.5, fillcolor='#FFDD33', opacity=0.3, layer='below', line_width=0),\n",
        "        # More vivid Salmon for [-0.5, 0] -> Changed to Lighter Yellow\n",
        "        dict(type='rect', xref='x', yref='y', x0=-0.5, y0=-0.5, x1=0, y1=0.5, fillcolor='#FFEE99', opacity=0.3, layer='below', line_width=0),\n",
        "        # More vivid Light Green for [0, 0.5] -> Changed to Light Blue\n",
        "        dict(type='rect', xref='x', yref='y', x0=0, y0=-0.5, x1=0.5, y1=0.5, fillcolor='#ADD8E6', opacity=0.3, layer='below', line_width=0),\n",
        "        # More vivid Darker Green for [0.5, 1] -> Changed to Darker Blue\n",
        "        dict(type='rect', xref='x', yref='y', x0=0.5, y0=-0.5, x1=1, y1=0.5, fillcolor='#4682B4', opacity=0.3, layer='below', line_width=0)\n",
        "    ]\n",
        ")\n",
        "\n",
        "fig_submitted_bar.add_trace(go.Bar(\n",
        "    x=[rb_index],\n",
        "    y=['SI'],\n",
        "    orientation='h',\n",
        "    base=0,\n",
        "    marker_color=bar_color_si,\n",
        "    text=f'{rb_index:.2f}',\n",
        "    textposition='inside',\n",
        "    textfont=dict(color='white'), # White text color\n",
        "    width=0.4 # Height of the indicator bar\n",
        "))\n",
        "\n",
        "fig_submitted_bar.update_layout(\n",
        "    title_text='Resolution Balance (RB)', # Updated title\n",
        "    xaxis_range=[-1, 1], # Set x-axis range strictly from -1 to 1\n",
        "    xaxis_title='← Planning | Implementing →', # Updated x-axis title\n",
        "    yaxis_visible=False, # Hide y-axis\n",
        "    yaxis_showticklabels=False, # Hide y-axis tick labels\n",
        "    height=150, # Set a reasonable height for the bar chart\n",
        "    width=800, # Set a reasonable width\n",
        "    margin=dict(l=20, r=20, t=50, b=20), # Adjust margins\n",
        "    title_x=0.5 # Center the title\n",
        ")\n",
        "\n",
        "fig_submitted_bar.show()\n",
        "\n",
        "save_fig(fig_submitted_bar, 'resolution_balance.html')\n"
      ],
      "metadata": {
        "id": "UhCJQCVaHK7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Develoment tide chart : WB x RB"
      ],
      "metadata": {
        "id": "iKfdKtcHTfb0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8vEIYLBZ9Pn"
      },
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "# 2. Create a Pandas DataFrame named df_metrics with 'EB' (submitted_index) and 'WB' (aggregate_pi)\n",
        "# Ensure rb_index and wb_index are available from previous cells\n",
        "df_metrics = pd.DataFrame({\n",
        "    'RB': [rb_index],\n",
        "    'WB': [wb_index]\n",
        "})\n",
        "\n",
        "# 1. Calculate the polar coordinates r (radius) and theta_degrees (angle in degrees)\n",
        "#    from the EB and WB values in df_metrics.\n",
        "df_metrics['r'] = np.sqrt(df_metrics['RB']**2 + df_metrics['WB']**2)\n",
        "df_metrics['theta_degrees'] = np.degrees(np.arctan2(df_metrics['RB'], df_metrics['WB']))\n",
        "\n",
        "# 2. Initialize the figure\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add a separate trace for the line from the origin to the point (added first to be in the background)\n",
        "fig.add_trace(go.Scatterpolar(\n",
        "    r=[0, df_metrics['r'].iloc[0]], # Draw line from origin (r=0) to the point's r\n",
        "    theta=[df_metrics['theta_degrees'].iloc[0], df_metrics['theta_degrees'].iloc[0]], # Maintain same angle\n",
        "    mode='lines',\n",
        "    line=dict(width=1, color='black', dash='dot'), # Updated line style: thin, black, dotted\n",
        "    name='Handle from Origin'\n",
        "))\n",
        "\n",
        "# Add the trace for the marker and its text (added second to be on top)\n",
        "fig.add_trace(go.Scatterpolar(\n",
        "    r=df_metrics['r'],\n",
        "    theta=df_metrics['theta_degrees'],\n",
        "    mode='markers+text', # Restored mode to markers+text\n",
        "    marker=dict(size=15, color='blue'),\n",
        "    text=[f'RB: {df_metrics['RB'].iloc[0]:.2f}<br>WB: {df_metrics['WB'].iloc[0]:.2f}'],\n",
        "    textposition='top center',\n",
        "    name='Current State'\n",
        "))\n",
        "\n",
        "# 3. Update the layout of the figure to configure the polar axes\n",
        "fig.update_layout(\n",
        "    title_text='Project tide chart (WB x RB)', # Updated title\n",
        "    title_x=0.5,\n",
        "    height=600,\n",
        "    width=800,\n",
        "    polar=dict(\n",
        "        radialaxis=dict(range=[0, 1.1]),\n",
        "        angularaxis=dict(\n",
        "            rotation=90, # To align 0 degrees with 'Up' (+WB)\n",
        "            direction='clockwise', # For clockwise angle increase\n",
        "            tickvals=[0, 90, 180, 270],\n",
        "            ticktext=['Clearing (+WB)', 'Implementing (+RB)', 'Accumulating (-WB)', 'Planning (-RB)']\n",
        "        )\n",
        "    ),\n",
        "    showlegend=False # Hide legend as it's a single point and handle\n",
        ")\n",
        "\n",
        "# 6. Display the plot\n",
        "fig.show()\n",
        "\n",
        "save_fig(fig, 'wb_rb_map.html')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PR completion-time in the period"
      ],
      "metadata": {
        "id": "ttI06KxRMSFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cellname : pr-close-time\n",
        "\n",
        "from datetime import datetime, timezone\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "# Ensure selected_timedelta and repo are available from previous cells\n",
        "end_date = datetime.now(timezone.utc)\n",
        "start_date = end_date - selected_timedelta\n",
        "\n",
        "pr_close_times = []\n",
        "\n",
        "# Initialize counters for the new categories\n",
        "opened_before_closed_in_period_count = 0\n",
        "opened_and_closed_in_period_count = 0\n",
        "opened_in_period_still_open_count = 0\n",
        "opened_before_still_open_count = 0\n",
        "\n",
        "print(f\"Analyzing PRs relative to the period: {start_date.strftime('%Y-%m-%d %H:%M:%S')} to {end_date.strftime('%Y-%m-%d %H:%M:%S')}...\")\n",
        "\n",
        "# Fetch ALL pull requests (both open and closed) for comprehensive analysis\n",
        "all_pulls = repo.get_pulls(state='all')\n",
        "\n",
        "for pull in all_pulls:\n",
        "    # Category: Opened before period and closed within period\n",
        "    if pull.created_at < start_date and pull.closed_at and start_date <= pull.closed_at <= end_date:\n",
        "        opened_before_closed_in_period_count += 1\n",
        "\n",
        "    # Category: Opened and closed in period\n",
        "    if start_date <= pull.created_at <= end_date and pull.closed_at and start_date <= pull.closed_at <= end_date:\n",
        "        opened_and_closed_in_period_count += 1\n",
        "        # Also add to pr_close_times for detailed analysis and histogram\n",
        "        time_to_close = pull.closed_at - pull.created_at\n",
        "        pr_close_times.append({\n",
        "            'number': pull.number,\n",
        "            'title': pull.title,\n",
        "            'creator': pull.user.login if pull.user else 'N/A',\n",
        "            'created_at': pull.created_at,\n",
        "            'closed_at': pull.closed_at,\n",
        "            'time_to_close_days': time_to_close.total_seconds() / (24 * 3600)\n",
        "        })\n",
        "\n",
        "    # Category: Opened in period and not yet closed\n",
        "    if start_date <= pull.created_at <= end_date and pull.closed_at is None:\n",
        "        opened_in_period_still_open_count += 1\n",
        "\n",
        "    # Category: Opened before period and still open\n",
        "    if pull.created_at < start_date and pull.closed_at is None:\n",
        "        opened_before_still_open_count += 1\n",
        "\n",
        "print(\"\\n--- PR Categorization for the Period ---\")\n",
        "print(f\"* PRs opened before period and closed in period: {opened_before_closed_in_period_count}\")\n",
        "print(f\"* PRs opened and closed in period: {opened_and_closed_in_period_count}\")\n",
        "print(f\"* PRs opened in period and not closed: {opened_in_period_still_open_count}\")\n",
        "print(f\"* PRs opened before period and still open: {opened_before_still_open_count}\")\n",
        "\n",
        "df_pr_close_times = pd.DataFrame(pr_close_times)\n",
        "\n",
        "if not df_pr_close_times.empty:\n",
        "    print(f\"\\nFound {len(df_pr_close_times)} PRs opened and closed within the period for detailed analysis.\")\n",
        "    display(df_pr_close_times.head())\n",
        "\n",
        "    print(\"\\n--- Summary of PR Close Times (Opened & Closed in Period) ---\")\n",
        "    print(f\"Average time to close PR: {df_pr_close_times['time_to_close_days'].mean():.2f} days\")\n",
        "    print(f\"Median time to close PR: {df_pr_close_times['time_to_close_days'].median():.2f} days\")\n",
        "    print(f\"Minimum time to close PR: {df_pr_close_times['time_to_close_days'].min():.2f} days\")\n",
        "    print(f\"Maximum time to close PR: {df_pr_close_times['time_to_close_days'].max():.2f} days\")\n",
        "\n",
        "    # Optional: Plotting a histogram of close times\n",
        "    fig = px.histogram(df_pr_close_times, x='time_to_close_days', nbins=10,\n",
        "                       title='PR completion-time histogram',\n",
        "                       labels={'time_to_close_days': 'Time to Close (Days)', 'count': 'Number of PRs'})\n",
        "    fig.show()\n",
        "    save_fig(fig, 'pr_close_times_histogram.html')\n",
        "else:\n",
        "    print(\"\\nNo PRs were opened and closed within the selected period for detailed time analysis.\")\n"
      ],
      "metadata": {
        "id": "20O31kzZMXxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "import pandas as pd\n",
        "\n",
        "# Ensure the df_pr_close_times DataFrame is not empty\n",
        "if not df_pr_close_times.empty:\n",
        "    # Create the scatter plot trace\n",
        "    scatter_trace = go.Scatter(\n",
        "        x=df_pr_close_times['number'],\n",
        "        y=df_pr_close_times['time_to_close_days'],\n",
        "        mode='markers',\n",
        "        marker=dict(size=10, opacity=0.8, line=dict(width=1, color='DarkSlateGrey')),\n",
        "        hoverinfo='text',\n",
        "        # Custom hover text to display detailed PR information\n",
        "        text=df_pr_close_times.apply(lambda row:\n",
        "            f\"PR #{row['number']}<br>\" +\n",
        "            f\"Title: {row['title']}<br>\" +\n",
        "            f\"Creator: {row['creator']}<br>\" +\n",
        "            f\"Created: {row['created_at'].strftime('%Y-%m-%d %H:%M:%S')}<br>\" +\n",
        "            f\"Closed: {row['closed_at'].strftime('%Y-%m-%d %H:%M:%S')}<br>\" +\n",
        "            f\"Time to Close: {row['time_to_close_days']:.2f} days\", axis=1)\n",
        "    )\n",
        "\n",
        "    # Create the figure and add the trace\n",
        "    fig = go.Figure(data=[scatter_trace])\n",
        "\n",
        "    # Calculate quartiles\n",
        "    q1 = df_pr_close_times['time_to_close_days'].quantile(0.25)\n",
        "    median = df_pr_close_times['time_to_close_days'].quantile(0.50)\n",
        "    q3 = df_pr_close_times['time_to_close_days'].quantile(0.75)\n",
        "\n",
        "    # Add horizontal lines for quartiles\n",
        "    fig.add_hline(y=q1, line_dash='dash', line_color='green', line_width=1, annotation_text=f\"Q1: {q1:.2f} days\", annotation_position=\"bottom right\")\n",
        "    fig.add_hline(y=median, line_dash='dash', line_color='blue', line_width=1, annotation_text=f\"Median: {median:.2f} days\", annotation_position=\"bottom right\")\n",
        "    fig.add_hline(y=q3, line_dash='dash', line_color='red', line_width=1, annotation_text=f\"Q3: {q3:.2f} days\", annotation_position=\"bottom right\")\n",
        "\n",
        "    # Update layout for title and axis labels\n",
        "    fig.update_layout(\n",
        "        title='PR completion time with quartiles',\n",
        "        xaxis_title='Pull Request Number',\n",
        "        yaxis_title='Time to Close (Days)',\n",
        "        height=600,\n",
        "        hovermode='closest' # Show hover info for the closest point\n",
        "    )\n",
        "\n",
        "    # Display the plot\n",
        "    fig.show()\n",
        "    save_fig(fig, 'pr_close_time_scatter_plot.html')\n",
        "else:\n",
        "    print(\"No PRs were opened and closed within the selected period to plot.\")\n"
      ],
      "metadata": {
        "id": "jMcVH9HESHeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "# Data from the previous cell's execution\n",
        "pr_category_data = {\n",
        "    'Category': [\n",
        "        'Opened before period & closed in period',\n",
        "        'Opened & closed in period',\n",
        "        'Opened in period & not closed',\n",
        "        'Opened before period & still open'\n",
        "    ],\n",
        "    'Count': [\n",
        "        opened_before_closed_in_period_count,\n",
        "        opened_and_closed_in_period_count,\n",
        "        opened_in_period_still_open_count,\n",
        "        opened_before_still_open_count\n",
        "    ]\n",
        "}\n",
        "\n",
        "df_pr_categories = pd.DataFrame(pr_category_data)\n",
        "\n",
        "# Filter out categories with 0 count to avoid empty slices\n",
        "df_pr_categories = df_pr_categories[df_pr_categories['Count'] > 0]\n",
        "\n",
        "if df_pr_categories.empty:\n",
        "    print(\"No PR activity found to categorize for the pie chart.\")\n",
        "else:\n",
        "    fig = px.pie(\n",
        "        df_pr_categories,\n",
        "        values='Count',\n",
        "        names='Category', # Use the raw category name for slice identification\n",
        "        title='Distribution of PR status',\n",
        "        hole=0.3, # Optional: creates a donut chart\n",
        "        color_discrete_sequence=px.colors.qualitative.Pastel # Use a pastel color sequence\n",
        "    )\n",
        "\n",
        "    fig.update_traces(\n",
        "        textposition='outside',\n",
        "        textinfo='percent+label+value',\n",
        "        textfont_color='black'\n",
        "        # Optional: rotate labels if they overlap\n",
        "        # insidetextorientation='radial'\n",
        "    )\n",
        "    fig.update_layout(\n",
        "        showlegend=True,\n",
        "        legend=dict(\n",
        "            orientation='h', # Horizontal orientation for bottom placement\n",
        "            yanchor='bottom',   # Anchor to the bottom\n",
        "            y=-0.3,             # Position further below the plot area\n",
        "            xanchor='center',\n",
        "            x=0.5              # Center horizontally\n",
        "        )\n",
        "    )\n",
        "    fig.show()\n",
        "    save_fig(fig, 'pr_categories_pie_chart.html')\n"
      ],
      "metadata": {
        "id": "74vrX9wPN94D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DEVELOPERS OVERVIEW"
      ],
      "metadata": {
        "id": "-PiwsbYFHJr3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Engagement"
      ],
      "metadata": {
        "id": "AV-VrWYcVCkz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Engament chart"
      ],
      "metadata": {
        "id": "K1gq1rrxJjgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cellname : engagement-plot\n",
        "\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "# Calculate the 'Discussion' metric\n",
        "df_plot_discussion = df_people.copy()\n",
        "df_plot_discussion['Discussion'] = df_plot_discussion['issues_opened_count'] + df_plot_discussion['issue_comment_event_count']\n",
        "\n",
        "# Filter out developers who have no activity in either PRs Opened or Discussion\n",
        "df_plot_discussion = df_plot_discussion[\n",
        "    (df_plot_discussion['pull_requests_opened_count'] > 0) |\n",
        "    (df_plot_discussion['Discussion'] > 0)\n",
        "].copy()\n",
        "\n",
        "# --- Aggregate data for unique (PRs Opened, Discussion) coordinates ---\n",
        "aggregated_df = df_plot_discussion.groupby(['pull_requests_opened_count', 'Discussion']).agg(\n",
        "    github_logins=('github_login', lambda x: ', '.join(x)),\n",
        "    names=('name', lambda x: ', '.join(x)),\n",
        "    num_devs=('github_login', 'count')\n",
        ").reset_index()\n",
        "\n",
        "# Create a unique key for each aggregated point for coloring with distinct discrete colors\n",
        "# This key will also be used initially as the legend name before being replaced by logins\n",
        "aggregated_df['point_category'] = 'PRs ' + aggregated_df['pull_requests_opened_count'].astype(str) + ', Discussion ' + aggregated_df['Discussion'].astype(str)\n",
        "\n",
        "# Add a new column to aggregated_df to determine marker style\n",
        "aggregated_df['marker_type'] = aggregated_df['num_devs'].apply(lambda x: 'Single Contributor' if x == 1 else 'Multiple Contributors')\n",
        "\n",
        "# Define a custom color sequence using only Dark24\n",
        "custom_color_sequence = px.colors.qualitative.Dark24\n",
        "\n",
        "# Create the scatter plot with aggregated data\n",
        "fig = px.scatter(\n",
        "    aggregated_df,\n",
        "    x='pull_requests_opened_count',\n",
        "    y='Discussion',\n",
        "    size='num_devs', # Size of marker based on number of developers at this point\n",
        "    color='point_category', # Use the categorical key for distinct colors\n",
        "    color_discrete_sequence=custom_color_sequence, # Use the custom, extended palette\n",
        "    symbol='marker_type', # Use the new column to determine marker symbol (solid vs. outlined)\n",
        "    symbol_map={'Single Contributor': 'circle', 'Multiple Contributors': 'circle-open'}, # Explicitly map styles\n",
        "    text=None, # Removed text labels from directly on the bubbles\n",
        "    title='Engagement chart',\n",
        "    labels={\n",
        "        'pull_requests_opened_count': 'PRs Opened',\n",
        "        'Discussion': 'Discussion (Issues Opened + Comments)',\n",
        "        'num_devs': 'Number of Contributors',\n",
        "        'github_logins': 'Contributors',\n",
        "        'point_category': 'Contributors' # This will be the initial legend title, replaced later\n",
        "    },\n",
        "    hover_name='names', # Show aggregated names on hover\n",
        "    hover_data={\n",
        "        'github_logins': True, # Also show aggregated logins on hover\n",
        "        'num_devs': True,\n",
        "        'pull_requests_opened_count': True,\n",
        "        'Discussion': True,\n",
        "        'names': False,\n",
        "        'point_category': False\n",
        "    }\n",
        ")\n",
        "\n",
        "# The update_traces for textposition will now do nothing as text=None\n",
        "# fig.update_traces(textposition='middle right', textfont_size=10)\n",
        "\n",
        "# Increase border thickness for 'circle-open' symbols, inheriting color\n",
        "fig.update_traces(marker=dict(line=dict(width=8, color='black')), selector=dict(symbol='circle-open'))\n",
        "\n",
        "# Create a mapping from point_category to github_logins for legend renaming\n",
        "category_to_logins_map = aggregated_df.set_index('point_category')['github_logins'].to_dict()\n",
        "\n",
        "# Function to extract the base point_category from the full trace name\n",
        "def get_base_point_category(full_trace_name):\n",
        "    # The trace name will be 'point_category_value, marker_type_value' if both color and symbol are used\n",
        "    # We want to split at the last comma to get 'point_category_value'\n",
        "    parts = full_trace_name.rsplit(', ', 1)\n",
        "    if len(parts) > 1 and (parts[-1] == 'Single Contributor' or parts[-1] == 'Multiple Contributors'):\n",
        "        return parts[0]\n",
        "    return full_trace_name # Fallback if name doesn't match expected pattern (e.g., if only color is used)\n",
        "\n",
        "# Update the legend entry names to show github_logins\n",
        "fig.for_each_trace(lambda trace: trace.update(name=category_to_logins_map[get_base_point_category(trace.name)]))\n",
        "\n",
        "fig.update_layout(\n",
        "    height=1200, # Increased height to accommodate the legend\n",
        "    xaxis_title='PRs Opened',\n",
        "    yaxis_title='Discussion (Issues Opened + Comments)',\n",
        "    legend_title='Contributors',\n",
        "    legend=dict(\n",
        "        orientation='v', # Vertical orientation\n",
        "        yanchor='top', # Anchor to the top\n",
        "        y=-0.2, # Position below the chart (adjust as needed)\n",
        "        xanchor='left',\n",
        "        x=0\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n",
        "save_fig(fig, 'engagement_plot.html')\n"
      ],
      "metadata": {
        "id": "hRXTbQz0J7LG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Engagement magnitude (EM) index"
      ],
      "metadata": {
        "id": "NSNiOp8IJqrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cellname : engagement-index\n",
        "\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Calculate the 'Discussion' metric if not already present\n",
        "df_bci = df_people.copy()\n",
        "df_bci['Discussion'] = df_bci['issues_opened_count'] + df_bci['issue_comment_event_count']\n",
        "\n",
        "# Filter out developers with BCI equal to 0 (no contributions in these categories)\n",
        "df_em_plot = df_bci[((df_bci['Discussion'] > 0) | (df_bci['pull_requests_opened_count'] > 0))].copy()\n",
        "\n",
        "# --- Normalize coordinates (Discussion, PRs Opened) between 0 and 1 ---\n",
        "max_discussion = df_em_plot['Discussion'].max()\n",
        "max_prs_opened = df_em_plot['pull_requests_opened_count'].max()\n",
        "\n",
        "df_em_plot['Normalized_Discussion'] = 0\n",
        "if max_discussion > 0:\n",
        "    df_em_plot['Normalized_Discussion'] = (df_em_plot['Discussion'] / max_discussion)\n",
        "\n",
        "df_em_plot['Normalized_PRs_Opened'] = 0\n",
        "if max_prs_opened > 0:\n",
        "    df_em_plot['Normalized_PRs_Opened'] = (df_em_plot['pull_requests_opened_count'] / max_prs_opened)\n",
        "\n",
        "# Calculate the Engagement Magnitude Index (EM) using normalized values\n",
        "# EM = sqrt(Normalized_Discussion^2 + Normalized_PRs_Opened^2)\n",
        "df_em_plot['EM'] = np.sqrt(df_em_plot['Normalized_Discussion']**2 + df_em_plot['Normalized_PRs_Opened']**2)\n",
        "\n",
        "# Normalize EM by its theoretical maximum of sqrt(2) to scale it between 0 and 1\n",
        "if not df_em_plot['EM'].empty:\n",
        "    df_em_plot['EM'] = df_em_plot['EM'] / np.sqrt(2)\n",
        "\n",
        "# Sort the DataFrame by EM in descending order\n",
        "df_em_plot = df_em_plot.sort_values(by='EM', ascending=False)\n",
        "\n",
        "# Create the bar chart for EM\n",
        "fig = px.bar(\n",
        "    df_em_plot,\n",
        "    x='github_login',\n",
        "    y='EM',\n",
        "    title='Engagement magnitude (EM) index',\n",
        "    labels={\n",
        "        'github_login': 'Contributor',\n",
        "        'EM': 'EM'\n",
        "    },\n",
        "    hover_name='name',\n",
        "    hover_data={\n",
        "        'github_login': False,\n",
        "        'name': True,\n",
        "        'Discussion': True,\n",
        "        'pull_requests_opened_count': True,\n",
        "        'Normalized_Discussion': ':.2f',\n",
        "        'Normalized_PRs_Opened': ':.2f',\n",
        "        'EM': ':.2f' # Format EM to 2 decimal places in hover\n",
        "    },\n",
        "    text_auto='.1f' # Format EM to 1 decimal place on top of bars\n",
        ")\n",
        "\n",
        "# Adjust x-axis to show labels vertically\n",
        "fig.update_xaxes(tickangle=90, tickfont=dict(size=10))\n",
        "fig.update_yaxes(rangemode='tozero') # Ensure y-axis starts at zero\n",
        "\n",
        "# Optional: adjust text position if needed (default 'auto' for bar usually puts it on top)\n",
        "fig.update_traces(textposition='outside')\n",
        "\n",
        "fig.show()\n",
        "\n",
        "save_fig(fig, 'em_index.html')\n"
      ],
      "metadata": {
        "id": "MqCBGuYoRC60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "REMI is the norm of the two-dimensional contribution vector whose coordinates are the developer’s Discussion score and the number of PRs opened. In practice, EMI captures the overall intensity of a developer’s participatory and initiatory actions by combining conversational engagement with concrete technical initiation into a single magnitude."
      ],
      "metadata": {
        "id": "COPik5GMUQbl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Delivery"
      ],
      "metadata": {
        "id": "wC_CR5-1jLym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Delivery chart"
      ],
      "metadata": {
        "id": "gSdZmkWKJ-Mb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cellname : deliery-plot\n",
        "\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "# Calculate the 'Code Changes' metric\n",
        "df_plot_code_changes = df_people.copy()\n",
        "df_plot_code_changes['Code Changes'] = df_plot_code_changes['total_additions'] + df_plot_code_changes['total_deletions']\n",
        "\n",
        "# Filter out developers who have no activity in either PRs Merged or Code Changes\n",
        "df_plot_code_changes = df_plot_code_changes[\n",
        "    (df_plot_code_changes['pull_requests_merged_count'] > 0) |\n",
        "    (df_plot_code_changes['Code Changes'] > 0)\n",
        "].copy()\n",
        "\n",
        "# --- Aggregate data for unique (PRs merged, Code Changes) coordinates ---\n",
        "aggregated_df = df_plot_code_changes.groupby(['pull_requests_merged_count', 'Code Changes']).agg(\n",
        "    github_logins=('github_login', lambda x: ', '.join(x)),\n",
        "    names=('name', lambda x: ', '.join(x)),\n",
        "    num_devs=('github_login', 'count')\n",
        ").reset_index()\n",
        "\n",
        "# Create a unique key for each aggregated point for coloring with distinct discrete colors\n",
        "aggregated_df['point_category'] = 'PRs Merged ' + aggregated_df['pull_requests_merged_count'].astype(str) + ', Changes ' + aggregated_df['Code Changes'].astype(str)\n",
        "\n",
        "# Add a new column to aggregated_df to determine marker style\n",
        "# Updated: 'circle' for single, 'circle-open' for multiple. 'circle-dot' would be third if needed.\n",
        "aggregated_df['marker_type'] = aggregated_df['num_devs'].apply(lambda x: 'Single Contributor' if x == 1 else 'Multiple Contributors')\n",
        "\n",
        "# Define a custom color sequence using only Dark24\n",
        "custom_color_sequence = px.colors.qualitative.Dark24\n",
        "\n",
        "# Create the scatter plot with aggregated data (axes swapped)\n",
        "fig = px.scatter(\n",
        "    aggregated_df,\n",
        "    x='Code Changes', # Swapped axis\n",
        "    y='pull_requests_merged_count', # Swapped axis\n",
        "    size='num_devs', # Size of marker based on number of developers at this point\n",
        "    color='point_category', # Use the categorical key for distinct colors\n",
        "    color_discrete_sequence=custom_color_sequence, # Use the custom, extended palette\n",
        "    symbol='marker_type', # Use the new column to determine marker symbol (solid vs. outlined)\n",
        "    symbol_map={'Single Contributor': 'circle', 'Multiple Contributors': 'circle-open'}, # Updated symbol_map\n",
        "    text=None, # Removed text labels from directly on the bubbles\n",
        "    title='Delivery chart',\n",
        "    labels={\n",
        "        'Code Changes': 'Code Changes (Additions + Deletions)', # Updated label\n",
        "        'pull_requests_merged_count': 'PRs Merged', # Updated label\n",
        "        'num_devs': 'Number of Contributors',\n",
        "        'github_logins': 'Contributors',\n",
        "        'point_category': 'Contributors' # This will be the initial legend title, replaced later\n",
        "    },\n",
        "    hover_name='names', # Show aggregated names on hover\n",
        "    hover_data={\n",
        "        'github_logins': True, # Also show aggregated logins on hover\n",
        "        'num_devs': True,\n",
        "        'pull_requests_merged_count': True,\n",
        "        'Code Changes': True,\n",
        "        'names': False, # Don't duplicate hover_name in hover_data\n",
        "        'point_category': False # Don't show this in hover data, as labels are clear\n",
        "    }\n",
        ")\n",
        "\n",
        "# Apply marker styling to ensure proportionality with small base size\n",
        "# sizeref: smaller value makes markers larger. Larger value makes markers smaller.\n",
        "# Let's target a max size of ~10 pixels for the largest 'num_devs' (reduced from 20)\n",
        "max_num_devs_val = aggregated_df['num_devs'].max()\n",
        "if max_num_devs_val > 0:\n",
        "    target_max_size = 10 # pixels for the largest bubble (reduced)\n",
        "    sizeref_val = max_num_devs_val / target_max_size\n",
        "else:\n",
        "    sizeref_val = 1 # avoid division by zero if all num_devs are 0 or 1\n",
        "\n",
        "fig.update_traces(\n",
        "    marker=dict(\n",
        "        sizemode='diameter', # Scale by diameter\n",
        "        sizeref=sizeref_val, # Reference value for scaling\n",
        "        sizemin=2,           # Minimum size in pixels for the smallest 'num_devs' (reduced from 4)\n",
        "        line=dict(width=1, color='DarkSlateGrey') # Default line for all\n",
        "    ),\n",
        "    selector=dict(mode='markers') # Apply to all scatter markers\n",
        ")\n",
        "\n",
        "# If specific line widths for symbols are desired, they can be added here\n",
        "# For example, to make the 'circle-open' slightly thicker outline\n",
        "fig.update_traces(marker=dict(line=dict(width=2)), selector=dict(symbol='circle-open'))\n",
        "\n",
        "\n",
        "# Create a mapping from point_category to github_logins for legend renaming\n",
        "category_to_logins_map = aggregated_df.set_index('point_category')['github_logins'].to_dict()\n",
        "\n",
        "# Function to extract the base point_category from the full trace name\n",
        "def get_base_point_category(full_trace_name):\n",
        "    # The trace name will be 'point_category_value, marker_type_value' if both color and symbol are used\n",
        "    # We want to split at the last comma to get 'point_category_value'\n",
        "    parts = full_trace_name.rsplit(', ', 1)\n",
        "    if len(parts) > 1 and (parts[-1] == 'Single Contributor' or parts[-1] == 'Multiple Contributors'):\n",
        "        return parts[0]\n",
        "    return full_trace_name # Fallback if name doesn't match expected pattern (e.g., if only color is used)\n",
        "\n",
        "# Update the legend entry names to show github_logins\n",
        "fig.for_each_trace(lambda trace: trace.update(name=category_to_logins_map[get_base_point_category(trace.name)]))\n",
        "\n",
        "fig.update_layout(\n",
        "    height=800, # Reduced height\n",
        "    xaxis_title='Code Changes (Additions + Deletions)', # Swapped axis title\n",
        "    yaxis_title='PRs Merged',\n",
        "    legend_title='Contributors',\n",
        "    legend=dict(\n",
        "        orientation='v', # Vertical orientation\n",
        "        yanchor='top', # Anchor to the top\n",
        "        y=-0.2, # Position below the chart (adjust as needed)\n",
        "        xanchor='left',\n",
        "        x=0\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n",
        "save_fig(fig, 'delivery_plot.html')\n"
      ],
      "metadata": {
        "id": "7HpAzvtSjkiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Delivery magnitude (DM) index\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DMKVzGH0KFNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cellname : delivery-index\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Calculate the 'Code Changes' metric if not already present\n",
        "df_dm = df_people.copy()\n",
        "df_dm['Code Changes'] = df_dm['total_additions'] + df_dm['total_deletions']\n",
        "\n",
        "# Filter out developers with no contributions in these categories\n",
        "df_dm_plot = df_dm[((df_dm['Code Changes'] > 0) | (df_dm['pull_requests_merged_count'] > 0))].copy()\n",
        "\n",
        "# --- Normalize coordinates (Code Changes, PRs Merged) between 0 and 1 ---\n",
        "max_code_changes = df_dm_plot['Code Changes'].max()\n",
        "max_prs_merged = df_dm_plot['pull_requests_merged_count'].max()\n",
        "\n",
        "df_dm_plot['Normalized_Code_Changes'] = 0\n",
        "if max_code_changes > 0:\n",
        "    df_dm_plot['Normalized_Code_Changes'] = (df_dm_plot['Code Changes'] / max_code_changes)\n",
        "\n",
        "df_dm_plot['Normalized_PRs_Merged'] = 0\n",
        "if max_prs_merged > 0:\n",
        "    df_dm_plot['Normalized_PRs_Merged'] = (df_dm_plot['pull_requests_merged_count'] / max_prs_merged)\n",
        "\n",
        "# Calculate the Delivery Magnitude Index (DM) using normalized values\n",
        "# DM = sqrt(Normalized_Code_Changes^2 + Normalized_PRs_Merged^2)\n",
        "df_dm_plot['DM'] = np.sqrt(df_dm_plot['Normalized_Code_Changes']**2 + df_dm_plot['Normalized_PRs_Merged']**2)\n",
        "\n",
        "# Normalize the final index value so that it fits in [0, 1]\n",
        "# The maximum possible value for DM is sqrt(1^2 + 1^2) = sqrt(2)\n",
        "if not df_dm_plot['DM'].empty:\n",
        "    df_dm_plot['DM'] = df_dm_plot['DM'] / np.sqrt(2)\n",
        "\n",
        "# Sort the DataFrame by DM in descending order\n",
        "df_dm_plot = df_dm_plot.sort_values(by='DM', ascending=False)\n",
        "\n",
        "# Create the bar chart for DM\n",
        "fig = px.bar(\n",
        "    df_dm_plot,\n",
        "    x='github_login',\n",
        "    y='DM',\n",
        "    title='Delivery magnitude (DM)',\n",
        "    labels={\n",
        "        'github_login': 'Contributor',\n",
        "        'DM': 'DM'\n",
        "    },\n",
        "    hover_name='name',\n",
        "    hover_data={\n",
        "        'github_login': False,\n",
        "        'name': True,\n",
        "        'Code Changes': True,\n",
        "        'pull_requests_merged_count': True,\n",
        "        'Normalized_Code_Changes': ':.2f',\n",
        "        'Normalized_PRs_Merged': ':.2f',\n",
        "        'DM': ':.2f' # Format to 2 decimal places in hover\n",
        "    },\n",
        "    text_auto='.1f' # Format to 1 decimal place on top of bars\n",
        ")\n",
        "\n",
        "# Adjust x-axis to show labels vertically\n",
        "fig.update_xaxes(tickangle=90, tickfont=dict(size=10))\n",
        "fig.update_yaxes(rangemode='tozero') # Ensure y-axis starts at zero\n",
        "\n",
        "# Adjust text position\n",
        "fig.update_traces(textposition='outside')\n",
        "\n",
        "fig.show()\n",
        "\n",
        "save_fig(fig, 'dm_index.html')\n"
      ],
      "metadata": {
        "id": "LpOgEhI0l-YY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Relative Delivery Magnitude Index (RDMI) is the norm of the two-dimensional delivery vector whose components are the developer’s code changes and the number of PRs merged. Conceptually, CDI represents the overall strength of a developer’s effective code delivery by combining the volume of code produced with the number of contributions successfully integrated into the project."
      ],
      "metadata": {
        "id": "k_rbDzl2qGkB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Engagement-Delivery Map"
      ],
      "metadata": {
        "id": "p_vKg9PGqfOx"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9240627d"
      },
      "source": [
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "# Ensure df_em_plot and df_dm_plot are available and contain the calculated indices\n",
        "# If this cell is run independently, ensure these DFs are regenerated or loaded\n",
        "\n",
        "# Select relevant columns from each DataFrame\n",
        "df_em = df_em_plot[['github_login', 'name', 'EM']]\n",
        "df_dm = df_dm_plot[['github_login', 'name', 'DM']]\n",
        "\n",
        "# Merge the two DataFrames on 'github_login'\n",
        "# Use an outer merge to include all contributors who appear in either index calculation\n",
        "df_combined_indices = pd.merge(df_em, df_dm,\n",
        "                               how='outer',\n",
        "                               on='github_login',\n",
        "                               suffixes=('_em', '_dm'))\n",
        "\n",
        "# Handle cases where a contributor might not have activity for one of the indices\n",
        "# (e.g., no PRs opened/comments for EM, or no code changes/PRs merged for DM)\n",
        "df_combined_indices['EM'] = df_combined_indices['EM'].fillna(0)\n",
        "df_combined_indices['DM'] = df_combined_indices['DM'].fillna(0)\n",
        "\n",
        "# Resolve potential duplicate 'name' columns if a simple merge was used.\n",
        "# We prefer the 'name' from the EM calculation, or the DM if the EM name is null/NA\n",
        "df_combined_indices['name'] = df_combined_indices['name_em'].fillna(df_combined_indices['name_dm'])\n",
        "\n",
        "# Drop the redundant name columns\n",
        "df_combined_indices = df_combined_indices.drop(columns=['name_em', 'name_dm'], errors='ignore')\n",
        "\n",
        "# Filter out contributors with zero in both indices for a cleaner plot, unless they are all zeros\n",
        "# Check if there's any non-zero value at all to decide on filtering\n",
        "if (df_combined_indices['EM'].sum() > 0) or (df_combined_indices['DM'].sum() > 0):\n",
        "    df_combined_indices_plot = df_combined_indices[\n",
        "        (df_combined_indices['EM'] > 0) |\n",
        "        (df_combined_indices['DM'] > 0)\n",
        "    ].copy()\n",
        "else:\n",
        "    df_combined_indices_plot = df_combined_indices.copy() # Keep all if all are zero\n",
        "\n",
        "\n",
        "# Create the scatter plot\n",
        "fig = px.scatter(\n",
        "    df_combined_indices_plot,\n",
        "    x='DM', # DM on X-axis\n",
        "    y='EM',                   # EM on Y-axis\n",
        "    text=None,       # Removed github_login as text on points\n",
        "    hover_name='name',         # Show full name on hover\n",
        "    hover_data={\n",
        "        'github_login': True, # Keep github_login in hover\n",
        "        'name': False,       # Don't duplicate hover_name\n",
        "        'EM': ':.2f',       # Format EM in hover\n",
        "        'DM': ':.2f' # Format DM in hover\n",
        "    },\n",
        "    title='Contribution chart (EM vs DM)',\n",
        "    labels={\n",
        "        'EM': 'Engagement Magnitude (EM)',\n",
        "        'DM': 'Delivery Magnitude (DM)'\n",
        "    },\n",
        "    # Removed 'size' from px.scatter to control it via update_traces\n",
        "    color='github_login', # Assign a unique color to each contributor\n",
        "    symbol='github_login' # Assign a unique symbol to each contributor\n",
        ")\n",
        "\n",
        "# Set a fixed, slightly larger size for all markers directly using update_traces\n",
        "fig.update_traces(marker=dict(size=10)) # Adjust 'size' to your desired pixel value\n",
        "\n",
        "# Removed textposition update as text labels are no longer desired\n",
        "# fig.update_traces(textposition='top center')\n",
        "\n",
        "# Add lines for quadrants\n",
        "fig.add_hline(y=0.5, line_dash='dash', line_color='gray', annotation_text=\"Average EM\")\n",
        "fig.add_vline(x=0.5, line_dash='dash', line_color='gray', annotation_text=\"Average DM\")\n",
        "\n",
        "# Update layout for better aesthetics and legend position\n",
        "fig.update_layout(\n",
        "    height=900, # Increased height to accommodate the legend below\n",
        "    width=900,\n",
        "    xaxis=dict(range=[-0.05, 1.05]), # Extend range slightly beyond 0-1\n",
        "    yaxis=dict(range=[-0.05, 1.05]),\n",
        "    showlegend=True, # Ensure legend is shown\n",
        "    legend=dict(\n",
        "        orientation='v', # Vertical orientation\n",
        "        yanchor='top',   # Anchor to the top of the legend container\n",
        "        y=1,             # Position at the top right (y=1) of the plot area\n",
        "        xanchor='right',\n",
        "        x=1             # Position slightly outside the plot area to the right\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "save_fig(fig, 'engagement_delivery_map.html')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Add REMI e RDMI to dataframe"
      ],
      "metadata": {
        "id": "gcLPjI8UM-B2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Select only the necessary columns from df_combined_indices\n",
        "df_indices_to_merge = df_combined_indices[['github_login', 'EM', 'DM']]\n",
        "\n",
        "# Ensure there are no existing BCI or Code_Delivery_Index columns in df_people\n",
        "# that would cause suffixing issues during merge. This is a more robust way to clean up.\n",
        "cols_to_remove = [col for col in df_people.columns if col.startswith('BCI') or col.startswith('Code_Delivery_Index') or col.startswith('EM') or col.startswith('DM')]\n",
        "if cols_to_remove:\n",
        "    df_people = df_people.drop(columns=cols_to_remove)\n",
        "\n",
        "# Merge with df_people to add EM and DM cleanly\n",
        "df_people = pd.merge(df_people, df_indices_to_merge,\n",
        "                     on='github_login',\n",
        "                     how='left') # Use left merge to keep all rows from df_people\n",
        "\n",
        "# Fill NaN values for EM and DM with 0 for contributors who had no activity\n",
        "# These lines should now succeed because the merge would have added the columns.\n",
        "df_people['EM'] = df_people['EM'].fillna(0.0)\n",
        "df_people['DM'] = df_people['DM'].fillna(0.0)\n",
        "\n",
        "print(\"df_people DataFrame com EM e DM adicionados:\")\n",
        "display(df_people.head())\n"
      ],
      "metadata": {
        "id": "gsoPL6-CMvcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1LgYy-TfM7mC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d481b19"
      },
      "source": [
        "## Engagement-Delivery distribution\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Engagement (EM) and Delivery (DM) stacked"
      ],
      "metadata": {
        "id": "qokwH3OJcEWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "# Select relevant columns from df_people\n",
        "df_plot_indices = df_people[['github_login', 'name', 'EM', 'DM']].copy()\n",
        "\n",
        "# Filter out developers who have zero for both EM and DM\n",
        "df_plot_indices_filtered = df_plot_indices[\n",
        "    (df_plot_indices['EM'] > 0) | (df_plot_indices['DM'] > 0)\n",
        "].copy()\n",
        "\n",
        "if df_plot_indices_filtered.empty:\n",
        "    print(\"No contributors with non-zero EM or DM scores found to plot.\")\n",
        "else:\n",
        "    # Calculate total score for sorting\n",
        "    df_plot_indices_filtered['total_score'] = df_plot_indices_filtered['EM'] + df_plot_indices_filtered['DM']\n",
        "\n",
        "    # Sort df_plot_indices_filtered by total_score in descending order\n",
        "    df_plot_indices_filtered = df_plot_indices_filtered.sort_values(by='total_score', ascending=False)\n",
        "\n",
        "    # Melt the DataFrame to a long format suitable for stacked bar charts\n",
        "    df_melted_indices = df_plot_indices_filtered.melt(\n",
        "        id_vars=['github_login', 'name', 'total_score'], # Include total_score for potential hover or sorting\n",
        "        value_vars=['EM', 'DM'],\n",
        "        var_name='Metric',\n",
        "        value_name='Value'\n",
        "    )\n",
        "\n",
        "    # Rename metrics for better readability in the plot\n",
        "    df_melted_indices['Metric'] = df_melted_indices['Metric'].replace({\n",
        "        'EM': 'EM (Engagement)',\n",
        "        'DM': 'DM (Delivery)'\n",
        "    })\n",
        "\n",
        "    # Custom order for metrics so EM is 'em baixo' and DM is 'acima'\n",
        "    metric_order = ['EM (Engagement)', 'DM (Delivery)']\n",
        "    df_melted_indices['Metric'] = pd.Categorical(df_melted_indices['Metric'], categories=metric_order, ordered=True)\n",
        "\n",
        "    # Get the sorted list of github_login for xaxis_categoryarray based on total_score\n",
        "    sorted_github_logins = df_plot_indices_filtered['github_login'].tolist()\n",
        "\n",
        "    # Create the stacked bar chart using Plotly Express\n",
        "    fig = px.bar(\n",
        "        df_melted_indices,\n",
        "        x='github_login',\n",
        "        y='Value',\n",
        "        color='Metric',\n",
        "        barmode='stack', # This creates stacked bars for each github_login\n",
        "        title='Contribution rank',\n",
        "        labels={\n",
        "            'github_login': 'Contributor',\n",
        "            'Value': 'Score',\n",
        "            'Metric': 'Index Type'\n",
        "        },\n",
        "        hover_name='name',\n",
        "        hover_data={\n",
        "            'github_login': True, # Keep github_login in hover for context\n",
        "            'name': False,       # Don't duplicate hover_name\n",
        "            'Metric': True,\n",
        "            'Value': ':.2f'      # Format Value to 2 decimal places in hover\n",
        "        },\n",
        "        text_auto='.2f' # Display text values automatically\n",
        "    )\n",
        "\n",
        "    # Refine plot aesthetics\n",
        "    fig.update_layout(\n",
        "        xaxis_title='Contributor',\n",
        "        yaxis_title='Score',\n",
        "        legend_title='Index Type',\n",
        "        xaxis_tickangle=90, # Rotate x-axis labels for readability\n",
        "        bargap=0.1, # Gap between groups of bars (not very relevant for stacked, but good practice)\n",
        "        height=600, # Adjust plot height\n",
        "        xaxis_categoryorder='array', # Preserve the order from the DataFrame\n",
        "        xaxis_categoryarray=sorted_github_logins\n",
        "    )\n",
        "\n",
        "    fig.update_yaxes(rangemode='tozero') # Ensure y-axis starts at zero\n",
        "\n",
        "    # Set text color to white for all traces and position text inside\n",
        "    fig.update_traces(textfont_color='white', textposition='inside')\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "    save_fig(fig, 'contribution_em_dm_plot.html')\n"
      ],
      "metadata": {
        "id": "qhmDWfUzRaD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Contribution score"
      ],
      "metadata": {
        "id": "uvG4IsTyRvzC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27c9c567"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. Calculate 'activity': A_factor * (EM>0) + (1-A_factor) * (DM>0)\n",
        "# Convert boolean to integer (True=1, False=0) for multiplication\n",
        "df_people['activity'] = (df_people['EM'] > 0).astype(int) * A_factor + \\\n",
        "                        (df_people['DM'] > 0).astype(int) * (1 - A_factor)\n",
        "\n",
        "# 2. Calculate 'reward' using the formula: R_factor * EM + (1-R_factor) * DM\n",
        "df_people['reward'] = (R_factor * df_people['EM']) + ((1 - R_factor) * df_people['DM'])\n",
        "\n",
        "# 3. Calculate the 'score' column as S_factor * activity + (1 - S_factor) * reward (range 0-1)\n",
        "df_people['score'] = S_factor * df_people['activity'] + (1 - S_factor) * df_people['reward']\n",
        "\n",
        "# Display the head of the df_people DataFrame to show the newly added 'activity', 'reward', and 'score' columns.\n",
        "display(df_people.head())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Contribution score (CS) plot"
      ],
      "metadata": {
        "id": "oXVlUy7xLyYT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c1ea2ce"
      },
      "source": [
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Ensure 'activity', 'reward', and 'score' columns are already calculated in df_people\n",
        "\n",
        "# Calculate the four individual components of the score\n",
        "df_people['score_component_activity_em_present'] = S_factor * A_factor * (df_people['EM'] > 0).astype(int)\n",
        "df_people['score_component_activity_dm_present'] = S_factor * (1 - A_factor) * (df_people['DM'] > 0).astype(int)\n",
        "df_people['score_component_reward_em_magnitude'] = (1 - S_factor) * R_factor * df_people['EM']\n",
        "df_people['score_component_reward_dm_magnitude'] = (1 - S_factor) * (1 - R_factor) * df_people['DM']\n",
        "\n",
        "# 1. Create a new DataFrame, df_contribution_plot, using the score components\n",
        "df_contribution_plot = df_people[[\n",
        "    'github_login', 'name', 'score',\n",
        "    'score_component_activity_em_present',\n",
        "    'score_component_activity_dm_present',\n",
        "    'score_component_reward_em_magnitude',\n",
        "    'score_component_reward_dm_magnitude'\n",
        "]].copy()\n",
        "\n",
        "# 2. Filter df_contribution_plot to include only contributors where score > 0\n",
        "df_contribution_plot = df_contribution_plot[df_contribution_plot['score'] > 0].copy()\n",
        "\n",
        "# 3. Melt df_contribution_plot into a long format suitable for stacking\n",
        "df_melted_score = df_contribution_plot.melt(\n",
        "    id_vars=['github_login', 'name', 'score'],\n",
        "    value_vars=[\n",
        "        'score_component_activity_em_present',\n",
        "        'score_component_activity_dm_present',\n",
        "        'score_component_reward_em_magnitude',\n",
        "        'score_component_reward_dm_magnitude'\n",
        "    ],\n",
        "    var_name='Component Type',\n",
        "    value_name='Value'\n",
        ")\n",
        "\n",
        "# 4. Rename component types for better plot labels\n",
        "df_melted_score['Component Type'] = df_melted_score['Component Type'].replace({\n",
        "    'score_component_activity_em_present': 'Activity (EM Present)',\n",
        "    'score_component_activity_dm_present': 'Activity (DM Present)',\n",
        "    'score_component_reward_em_magnitude': 'Reward (EM Magnitude)',\n",
        "    'score_component_reward_dm_magnitude': 'Reward (DM Magnitude)'\n",
        "})\n",
        "\n",
        "# 5. Sort the melted DataFrame by total score in descending order\n",
        "df_melted_score = df_melted_score.sort_values(by='score', ascending=False)\n",
        "\n",
        "# Get the sorted list of github_login for xaxis_categoryarray\n",
        "sorted_github_logins_for_score = df_melted_score['github_login'].unique().tolist()\n",
        "\n",
        "# Define custom colors for the components\n",
        "# Two shades of blue for activity components, two shades of green for reward components\n",
        "component_colors = {\n",
        "    'Activity (EM Present)': '#2A52BE',  # Darker Blue\n",
        "    'Activity (DM Present)': '#6495ED',  # Slightly darker CornflowerBlue\n",
        "    'Reward (EM Magnitude)': '#228B22',  # Darker Green (ForestGreen)\n",
        "    'Reward (DM Magnitude)': '#66CDAA'   # Slightly darker MediumAquamarine\n",
        "}\n",
        "\n",
        "# Define component order for consistent stacking\n",
        "component_order = [\n",
        "    'Activity (EM Present)',\n",
        "    'Activity (DM Present)',\n",
        "    'Reward (EM Magnitude)',\n",
        "    'Reward (DM Magnitude)'\n",
        "]\n",
        "df_melted_score['Component Type'] = pd.Categorical(df_melted_score['Component Type'], categories=component_order, ordered=True)\n",
        "\n",
        "# 6. Create a stacked bar chart using Plotly Express\n",
        "fig = px.bar(\n",
        "    df_melted_score,\n",
        "    x='github_login',\n",
        "    y='Value',\n",
        "    color='Component Type',\n",
        "    color_discrete_map=component_colors, # Apply custom colors\n",
        "    barmode='stack',\n",
        "    title='Contribution score breakdown',\n",
        "    labels={\n",
        "        'github_login': 'Contributor',\n",
        "        'Value': 'Score Component Value',\n",
        "        'Component Type': 'Score Component'\n",
        "    },\n",
        "    hover_name='name',\n",
        "    hover_data={\n",
        "        'github_login': True,\n",
        "        'name': False,\n",
        "        'Component Type': True,\n",
        "        'Value': ':.2f', # Format component value to 2 decimal places\n",
        "        'score': ':.2f' # Display total score in hover to 2 decimal places\n",
        "    },\n",
        "    text_auto='.2f', # Display component values on top of bars, formatted to 2 decimal places\n",
        "    category_orders={'Component Type': component_order} # Explicitly set stacking order for color variable\n",
        ")\n",
        "\n",
        "# Add total score as text on top of each bar\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=df_contribution_plot['github_login'],\n",
        "    y=df_contribution_plot['score'],\n",
        "    mode='text',\n",
        "    text=[f'{s:.2f}' for s in df_contribution_plot['score']], # Format total score to 2 decimal places\n",
        "    textposition='top center',\n",
        "    textfont=dict(color='black', size=10),\n",
        "    showlegend=False,\n",
        "    hoverinfo='none'\n",
        "))\n",
        "\n",
        "# f. Adjust the x-axis to show labels vertically and preserve the order from the sorted DataFrame\n",
        "fig.update_xaxes(tickangle=-90, tickfont=dict(size=10),\n",
        "                 categoryorder='array',\n",
        "                 categoryarray=sorted_github_logins_for_score)\n",
        "\n",
        "# g. Ensure the y-axis starts at zero (`rangemode='tozero'`) and has a maximum range slightly above 1\n",
        "fig.update_yaxes(rangemode='tozero', title_text='Score', range=[0, 1.1]) # Adjusted range to 0-1.1\n",
        "\n",
        "# h. Display the Value on top of the bars in white text, positioned inside (for components)\n",
        "fig.update_traces(textfont_color='white', textposition='inside', selector=dict(type='bar'))\n",
        "\n",
        "# Add horizontal dashed line at 0.5\n",
        "fig.add_hline(y=0.5, line_dash='dash', line_color='black', line_width=1.5)\n",
        "\n",
        "# Display the plot\n",
        "fig.show()\n",
        "\n",
        "print(\"Overall Score calculation and stacked bar chart generation complete.\")\n",
        "save_fig(fig, 'score_plot.html')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Score percentiles"
      ],
      "metadata": {
        "id": "owgCNExyL772"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "# Filter out contributors with a score of 0 for a more meaningful quartile analysis\n",
        "df_active_scores = df_people[df_people['score'] > 0].copy()\n",
        "\n",
        "if df_active_scores.empty:\n",
        "    print(\"No contributors with a score > 0 found to plot quartiles.\")\n",
        "else:\n",
        "    # Create a box plot for the 'score'\n",
        "    fig = px.box(\n",
        "        df_active_scores,\n",
        "        y='score',\n",
        "        title='Contribution score percentiles',\n",
        "        labels={\n",
        "            'score': 'Contribution Score'\n",
        "        },\n",
        "        hover_data={'github_login': True, 'name': True, 'score': ':.2f'}\n",
        "    )\n",
        "\n",
        "    # Customize layout for better readability\n",
        "    fig.update_layout(\n",
        "        yaxis_title='Score',\n",
        "        yaxis_range=[0, 1], # Ensure y-axis covers the full score range from 0 to 1\n",
        "        yaxis=dict(dtick=0.1), # Set grid lines every 0.1 units\n",
        "        boxmode='overlay' # Overlay points if multiple boxes (not applicable for single score column)\n",
        "    )\n",
        "\n",
        "    # Add individual data points as a scatter plot overlay (optional, for detail)\n",
        "    fig.add_trace(px.scatter(\n",
        "        df_active_scores,\n",
        "        y='score',\n",
        "        hover_name='name',\n",
        "        hover_data={'github_login': True, 'name': True, 'score': ':.2f'}\n",
        "    ).data[0])\n",
        "\n",
        "    fig.show()\n",
        "    save_fig(fig, 'score_percentiles_box_plot.html')\n",
        "\n",
        "    print(\"Box plot for contributor scores generated.\")\n",
        "\n",
        "    # Print quartile values with explanations\n",
        "    q1 = df_active_scores['score'].quantile(0.25)\n",
        "    median = df_active_scores['score'].quantile(0.50)\n",
        "    q3 = df_active_scores['score'].quantile(0.75)\n",
        "    max_score = df_active_scores['score'].max()\n",
        "    min_score = df_active_scores['score'].min()\n",
        "\n",
        "    print(\"\\n--- Contributor Score Quartiles ---\")\n",
        "    print(f\"* The lowest active score is: {min_score:.2f}\")\n",
        "    print(f\"* 25% of contributors have a score up to: {q1:.2f}\")\n",
        "    print(f\"* 50% of contributors (the median) have a score up to: {median:.2f}\")\n",
        "    print(f\"* 75% of contributors have a score up to: {q3:.2f}\")\n",
        "    print(f\"* The highest active score is: {max_score:.2f}\")\n"
      ],
      "metadata": {
        "id": "ZwrwQ2Fc8zQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Score histogram"
      ],
      "metadata": {
        "id": "LTb600wcMC9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "# Filter out contributors with a score of 0 for a more meaningful histogram\n",
        "df_active_scores_hist = df_people[df_people['score'] > 0].copy()\n",
        "\n",
        "if df_active_scores_hist.empty:\n",
        "    print(\"No contributors with a score > 0 found to plot a histogram.\")\n",
        "else:\n",
        "    # Create a histogram for the 'score'\n",
        "    fig = px.histogram(\n",
        "        df_active_scores_hist,\n",
        "        x='score',\n",
        "        nbins=20, # Adjust number of bins as needed\n",
        "        title='Contribution score histogram',\n",
        "        labels={\n",
        "            'score': 'Contribution Score',\n",
        "            'count': 'Number of Contributors'\n",
        "        },\n",
        "        hover_data={'name': True, 'score': ':.2f'}\n",
        "    )\n",
        "\n",
        "    # Customize layout for better readability\n",
        "    fig.update_layout(\n",
        "        xaxis_title='Contribution Score',\n",
        "        yaxis_title='Number of Contributors',\n",
        "        xaxis_range=[0, 1], # Ensure x-axis covers the full score range\n",
        "        bargap=0.1 # Gap between bars\n",
        "    )\n",
        "\n",
        "    # Calculate mean and median\n",
        "    mean_score = df_active_scores_hist['score'].mean()\n",
        "    median_score = df_active_scores_hist['score'].median()\n",
        "\n",
        "    # Add mean line\n",
        "    fig.add_vline(x=mean_score, line_width=2, line_dash=\"dash\", line_color=\"red\",\n",
        "                  annotation_text=f\"Mean: {mean_score:.2f}\",\n",
        "                  annotation_position=\"top right\")\n",
        "\n",
        "    # Add median line\n",
        "    fig.add_vline(x=median_score, line_width=2, line_dash=\"dot\", line_color=\"green\",\n",
        "                  annotation_text=f\"Median: {median_score:.2f}\",\n",
        "                  annotation_position=\"top left\")\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "    print(\"Histogram for contributor scores generated.\")\n",
        "    save_fig(fig, 'score_histogram.html')\n"
      ],
      "metadata": {
        "id": "QoHhfca4-9Lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Score proportions"
      ],
      "metadata": {
        "id": "fwIf_NaqMKyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cellname : scopre-pizza\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Categorize the 'score' column with new names\n",
        "def categorize_score(score):\n",
        "    if score == 0:\n",
        "        return 'Zero (score = 0)'\n",
        "    elif 0 < score < 0.5:\n",
        "        return 'Low (0 < score < 0.5)'\n",
        "    else:\n",
        "        return 'Good (0.5 <= score)'\n",
        "\n",
        "df_people['score_category'] = df_people['score'].apply(categorize_score)\n",
        "\n",
        "# 2. Count the occurrences in each category\n",
        "score_counts = df_people['score_category'].value_counts().reset_index()\n",
        "score_counts.columns = ['Category', 'Count']\n",
        "\n",
        "# 3. Define custom colors for the categories\n",
        "category_colors = {\n",
        "    'Zero (score = 0)': '#aaaa80',       # Lighter gray\n",
        "    'Low (0 < score < 0.5)': 'darkred',    # Darker red\n",
        "    'Good (0.5 <= score)': 'darkcyan'            # Cyan\n",
        "}\n",
        "\n",
        "# Ensure category order for consistent plotting\n",
        "category_order = ['Good (0.5 <= score)', 'Low (0 < score < 0.5)', 'Zero (score = 0)']\n",
        "score_counts['Category'] = pd.Categorical(score_counts['Category'], categories=category_order, ordered=True)\n",
        "score_counts = score_counts.sort_values('Category')\n",
        "\n",
        "# 5. Create the pie chart\n",
        "fig = px.pie(\n",
        "    score_counts,\n",
        "    values='Count',\n",
        "    names='Category', # Use the raw category name for slice identification\n",
        "    title='Contribution score ranges',\n",
        "    color='Category',\n",
        "    color_discrete_map=category_colors,\n",
        "    hover_data=['Count', 'Category']\n",
        ")\n",
        "\n",
        "# Update traces to show percentage and formatted name as text, outside\n",
        "fig.update_traces(textposition='outside', textinfo='percent', texttemplate=\"<b>%{label}</b><br>%{percent:.1%}<br>(%{value})\", textfont_color='black')\n",
        "\n",
        "fig.show()\n",
        "save_fig(fig, 'score_proportions_pie_chart.html')\n"
      ],
      "metadata": {
        "id": "oSlIzi-j_bOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aggregate indices"
      ],
      "metadata": {
        "id": "4gRWxSFkJkEh"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVns6OnoJu2u"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "\n",
        "# Prepare the data for quartile analysis\n",
        "# Use the original activity and reward values, which are already normalized 0-1\n",
        "df_people_quartiles = df_people.copy()\n",
        "\n",
        "# Select the relevant columns for the box plots\n",
        "metrics_for_quartiles = df_people_quartiles[['github_login', 'EM', 'DM', 'activity', 'reward']]\n",
        "\n",
        "# Filter out contributors who have 0 across all these metrics for meaningful quartiles\n",
        "df_active_metrics = metrics_for_quartiles[\n",
        "    (metrics_for_quartiles['EM'] > 0) |\n",
        "    (metrics_for_quartiles['DM'] > 0) |\n",
        "    (metrics_for_quartiles['activity'] > 0) |\n",
        "    (metrics_for_quartiles['reward'] > 0)\n",
        "].copy()\n",
        "\n",
        "if df_active_metrics.empty:\n",
        "    print(\"No active contributors found to display quartile distributions.\")\n",
        "else:\n",
        "    # Melt the DataFrame to a long format suitable for px.box for side-by-side plots\n",
        "    df_melted_metrics = df_active_metrics.melt(\n",
        "        id_vars=['github_login'],\n",
        "        value_vars=['EM', 'DM', 'activity', 'reward'],\n",
        "        var_name='Metric',\n",
        "        value_name='Value'\n",
        "    )\n",
        "\n",
        "    # Rename metrics for better display in the plot\n",
        "    df_melted_metrics['Metric'] = df_melted_metrics['Metric'].replace({\n",
        "        'EM': 'EM (Engagement)',\n",
        "        'DM': 'DM (Delivery)',\n",
        "        'activity': 'Activity',\n",
        "        'reward': 'Reward'\n",
        "    })\n",
        "\n",
        "    # Define explicit order for metrics for consistent plotting\n",
        "    metric_order = ['EM (Engagement)', 'DM (Delivery)', 'Activity', 'Reward']\n",
        "    df_melted_metrics['Metric'] = pd.Categorical(df_melted_metrics['Metric'], categories=metric_order, ordered=True)\n",
        "\n",
        "    # Create the box plot\n",
        "    fig = px.box(df_melted_metrics,\n",
        "                 x='Metric',\n",
        "                 y='Value',\n",
        "                 color='Metric', # Color boxes by metric type\n",
        "                 title='Quartile distribution of tide metrics',\n",
        "                 labels={'Metric': 'Metric', 'Value': 'Value'}, # Updated labels to English\n",
        "                 hover_data={'github_login': True, 'Value': ':.2f'},\n",
        "                 points='all' # Display all individual points\n",
        "                )\n",
        "\n",
        "    # Customize layout\n",
        "    fig.update_layout(\n",
        "        xaxis_title='Metric',\n",
        "        yaxis_title='Value',\n",
        "        xaxis_tickangle=-45,\n",
        "        height=600,\n",
        "        showlegend=False, # Legend not needed as colors are explained by x-axis\n",
        "        yaxis_range=[0, 1], # Set y-axis range to 0-1\n",
        "        yaxis=dict(dtick=0.1)\n",
        "    )\n",
        "\n",
        "    fig.show()\n",
        "    save_fig(fig, 'metric_quartiles_box_plot.html')\n",
        "\n",
        "    print(\"\\n--- Quartile Values for Each Metric ---\")\n",
        "    for metric in ['EM', 'DM', 'activity', 'reward']:\n",
        "        series = df_active_metrics[metric]\n",
        "        if not series.empty:\n",
        "            q1 = series.quantile(0.25)\n",
        "            median = series.quantile(0.50)\n",
        "            q3 = series.quantile(0.75)\n",
        "            max_val = series.max()\n",
        "            min_val = series.min()\n",
        "            mean_val = series.mean()\n",
        "\n",
        "            print(f\"\\nMetric: {metric.replace('EM', 'Engagement Magnitude').replace('DM', 'Delivery Magnitude')}\")\n",
        "            print(f\"  Mean: {mean_val:.2f}\")\n",
        "            print(f\"  Min: {min_val:.2f}\")\n",
        "            print(f\"  Q1 (25th percentile): {q1:.2f}\")\n",
        "            print(f\"  Median (50th percentile): {median:.2f}\")\n",
        "            print(f\"  Q3 (75th percentile): {q3:.2f}\")\n",
        "            print(f\"  Max: {max_val:.2f}\")\n",
        "        else:\n",
        "            print(f\"\\nMetric: {metric.replace('EM', 'Engagement Magnitude').replace('DM', 'Delivery Magnitude')} - No active data.\")\n"
      ],
      "metadata": {
        "id": "Iyr7mFnRPFaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OTHER INFORMATION"
      ],
      "metadata": {
        "id": "rwx4NtErqm9i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inactive developers\n",
        "\n",
        "* Devs that didn't contribute dureing the period"
      ],
      "metadata": {
        "id": "hJsOxwYrxDHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Define the columns that represent contribution events\n",
        "contribution_columns = [\n",
        "    'issues_opened_count',\n",
        "    'issues_reopened_count',\n",
        "    'issue_comment_event_count',\n",
        "    'pull_requests_opened_count',\n",
        "    'pull_requests_merged_count',\n",
        "    'pull_requests_closed_count',\n",
        "    'total_additions',\n",
        "    'total_deletions'\n",
        "]\n",
        "\n",
        "# Ensure all contribution columns exist in df_people\n",
        "existing_contribution_columns = [col for col in contribution_columns if col in df_people.columns]\n",
        "\n",
        "# Calculate the total contributions for each person\n",
        "# Summing across relevant columns for each row\n",
        "df_people['total_contributions'] = df_people[existing_contribution_columns].sum(axis=1)\n",
        "\n",
        "# Filter for developers with zero total contributions\n",
        "inactive_devs_df = df_people[df_people['total_contributions'] == 0]\n",
        "\n",
        "# Extract logins of inactive developers for potential future use\n",
        "inactive_dev_logins = inactive_devs_df['github_login'].tolist()\n",
        "\n",
        "if not inactive_devs_df.empty:\n",
        "    display(Markdown(f\"**{len(inactive_devs_df)} Developer(s) with No Contributions in the Period:**\"))\n",
        "    for index, row in inactive_devs_df.iterrows():\n",
        "        dev_name = row['name'] if row['name'] != 'N/A' else 'Name not available'\n",
        "        display(Markdown(f\"- {row['github_login']} ({dev_name})\"))\n",
        "else:\n",
        "    display(Markdown(\"**All developers have made at least one contribution in the selected period!**\"))\n",
        "\n",
        "# Clean up the temporary column\n",
        "df_people.drop(columns=['total_contributions'], inplace=True, errors='ignore')\n"
      ],
      "metadata": {
        "id": "VlRkZekRxIgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SAVE DATAFRAME"
      ],
      "metadata": {
        "id": "RUW6B0WSYNS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Ensure output_folder and df_people are defined from previous cells\n",
        "\n",
        "output_csv_path = os.path.join(output_folder, 'developers_data.csv')\n",
        "df_people.to_csv(output_csv_path, index=False)\n",
        "\n",
        "print(f\"DataFrame 'df_people' successfully saved to {output_csv_path}\")"
      ],
      "metadata": {
        "id": "wDyjsPjMYPcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CREATE REPORT"
      ],
      "metadata": {
        "id": "n2ibWwvZIh3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section descriptions"
      ],
      "metadata": {
        "id": "8yP1L3_DX17J"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "report_descriptions"
      },
      "source": [
        "# --- Report Description Variables ---\n",
        "\n",
        "# Project Summary\n",
        "summary_description = \"This section provides a high-level overview of the GitHub repository, including its basic metadata and general statistics.\"\n",
        "\n",
        "# Project Overview\n",
        "overview_description = \"This section summarizes the key demographic data for contributors and collaborators within the analyzed period.\"\n",
        "\n",
        "# Inactive Developers\n",
        "inactive_devs_description = \"This section lists developers who are either collaborators or external contributors but did not record any activity (issues opened/reopened, comments, PRs opened/merged, code changes) within the selected analysis period.\"\n",
        "inactive_devs_found_text = \"Developer(s) with No Contributions in the Period:\"\n",
        "inactive_devs_none_text = \"All developers have made at least one contribution in the selected period!\"\n",
        "\n",
        "# All Primitive Events\n",
        "primitive_events_description = \"This chart displays the raw count of various GitHub events (issues opened, issues reopened, comments, PRs opened, PRs merged, lines added, lines removed) per contributor. It provides a granular view of individual developer activity.\"\n",
        "\n",
        "# All Aggregate Events\n",
        "aggregate_events_description = \"This chart aggregates primitive events into broader categories: 'Issues Raised' (opened + reopened), 'Comments' (on issues/PRs), 'PRs Opened', 'PRs Merged', and 'Code Changes' (additions + deletions). It offers a summarized view of contribution types.\"\n",
        "\n",
        "# WB\n",
        "wbi_description = \"The WB (Workload Balance), calculated as (PRs Closed - PRs Opened) / (PRs Closed + PRs Opened), measures the balance between new work introduced (PRs opened) and work completed (PRs closed) in the project. A positive value indicates clearing the backlog, while a negative value suggests accumulation.\"\n",
        "\n",
        "# RB\n",
        "rbi_description = \"The RB (Resolution Balance), calculated as (PRs Submitted - Issues Raised) / (PRs Submitted + Issues Raised), reflects the balance between problem identification (issues raised) and solution implementation (PRs submitted). A positive value implies a focus on implementation, while a negative value suggests more issues are being identified than solutions proposed.\"\n",
        "\n",
        "# Project Performance Map\n",
        "performance_map_description = \"This map plots the Workload Balance (WB) against the Resolution Balance (RB) on a polar coordinate system. It visually represents the overall project dynamics, indicating whether the team is accumulating/clearing work and focusing on planning/implementing tasks.\"\n",
        "\n",
        "# PRs Close Time section\n",
        "pr_close_time_description = \"This section analyzes the lifecycle of Pull Requests, specifically focusing on the time taken to close them. It categorizes PRs based on their creation and closure dates relative to the analysis period.\"\n",
        "\n",
        "# Developers Overview - Engagement\n",
        "engagement_plot_description = \"This plot visualizes individual contributor engagement by mapping 'PRs Opened' against 'Discussion' (Issues Opened + Comments). It helps identify developers who are more conversational versus those focused on initiating code contributions.\"\n",
        "remi_index_description = \"EM quantifies a developer's overall engagement by taking the Euclidean norm of their normalized 'Discussion' and 'PRs Opened' scores. It intuitively measures the intensity of a developer's participatory and initiatory actions, ranging from 0 (no engagement) to 1 (maximum engagement).\"\n",
        "\n",
        "# Developers Overview - Delivery\n",
        "delivery_plot_description = \"This plot visualizes individual contributor delivery by mapping 'Code Changes' (lines added + deleted) against 'PRs Merged'. It helps identify developers who are generating significant code volume versus those focused on successfully integrating code into the main branch.\"\n",
        "rdmi_index_description = \"DM quantifies a developer's overall delivery by taking the Euclidean norm of their normalized 'Code Changes' and 'PRs Merged' scores. It intuitively measures the overall strength of a developer's effective code delivery, ranging from 0 (no delivery) to 1 (maximum delivery).\"\n",
        "\n",
        "# Engagement-Delivery Map\n",
        "engagement_delivery_map_description = \"This map plots each developer's EM against their DM score. It categorizes developers based on their relative engagement and delivery levels, helping identify different contributor profiles (e.g., highly engaged/low delivery vs. low engagement/high delivery).\"\n",
        "\n",
        "# Contribution (EM+DM) Plot\n",
        "contribution_plot_description = \"This stacked bar chart displays each developer's EM and DM scores side-by-side. It offers a combined view of individual engagement and delivery magnitudes, allowing for quick comparison across contributors.\"\n",
        "\n",
        "# Score Plot\n",
        "score_plot_description = \"The overall score for each contributor is calculated as a weighted sum of 'Activity' and 'Reward', using the formula `S * Activity + (1 - S) * Reward`. This provides a comprehensive measure between 0 and 1. 'Activity' measures minimal participation, while 'Reward' measures participation intensity based on EM and DM. This chart displays the stacked components of 'Activity' and 'Reward' contributing to the total score.\"\n",
        "score_percentiles_description = \"This box plot visualizes the distribution of individual contributor scores, showing quartiles (25th, 50th, 75th percentiles), minimum, and maximum values. It helps in understanding the spread and central tendency of scores across active developers.\"\n",
        "score_histogram_description = \"This histogram shows the frequency distribution of contributor scores, indicating how many developers fall within specific score ranges. It helps identify patterns in scoring, such as concentration around certain values or presence of multiple peaks.\"\n",
        "score_proportions_description = \"This pie chart categorizes contributors into three score ranges: 'Zero' (score = 0), 'Low' (0 < score < 0.5), and 'Good' (0.5 <= score). It illustrates the proportion of developers in each category, providing a high-level overview of the team's overall performance distribution.\"\n",
        "\n",
        "# Aggregate Indices\n",
        "metric_quartiles_description = \"This box plot displays the quartile distribution (25th, 50th, 75th percentiles) of individual EM, DM, Activity, and Reward scores across all active contributors. It provides insights into the spread and central tendency of these key metrics among developers.\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Report structure"
      ],
      "metadata": {
        "id": "vQjWJKeRXws7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bd54d58"
      },
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Ensure output_folder is defined from previous cells\n",
        "# output_folder = '/content/gdrive/My Drive/devstats_report' # Uncomment if running this cell independently\n",
        "\n",
        "html_content_parts = []\n",
        "\n",
        "# Ensure analysis_run_date is available. It should be defined in a preceding cell.\n",
        "# Add a safety check for analysis_run_date\n",
        "if 'analysis_run_date' not in globals():\n",
        "    analysis_run_date = \"Analysis date not available - please run the 'Get repository info' cell.\" # Fallback\n",
        "    print(\"Warning: 'analysis_run_date' not found. Using fallback message.\")\n",
        "\n",
        "print(f\"Using analysis_run_date for report: {analysis_run_date}\")\n",
        "\n",
        "# 1. HTML Head and Styles\n",
        "html_content_parts.append(f\"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>Project Report: {repo.name}</title>\n",
        "    <style>\n",
        "        body {{\n",
        "            font-family: 'Arial', sans-serif;\n",
        "            margin: 0;\n",
        "            padding: 20px;\n",
        "            background-color: #f4f7f6;\n",
        "            color: #333;\n",
        "            line-height: 1.6;\n",
        "        }}\n",
        "        .container {{\n",
        "            max-width: 1200px;\n",
        "            margin: 20px auto;\n",
        "            background-color: #ffffff;\n",
        "            padding: 30px;\n",
        "            border-radius: 8px;\n",
        "            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\n",
        "        }}\n",
        "        h1, h2, h3, h4, h5, h6 {{\n",
        "            color: #2c3e50;\n",
        "        }}\n",
        "        h1 {{\n",
        "            text-align: center;\n",
        "            color: #2196f3;\n",
        "            margin-bottom: 30px;\n",
        "        }}\n",
        "        .section {{\n",
        "            margin-bottom: 40px;\n",
        "            border-bottom: 1px solid #eee;\n",
        "            padding-bottom: 20px;\n",
        "        }}\n",
        "        .section:last-child {{\n",
        "            border-bottom: none;\n",
        "        }}\n",
        "        .figure-container {{\n",
        "            max-width: 1000px; /* Increased max-width for centering wider iframes */\n",
        "            margin: 20px auto; /* Center the figure container itself */\n",
        "            text-align: center; /* Center inline content like h3 */\n",
        "            border: 1px solid #ddd;\n",
        "            padding: 15px;\n",
        "            border-radius: 5px;\n",
        "            background-color: #f9f9f9;\n",
        "        }}\n",
        "        .figure-container h3 {{\n",
        "            margin-top: 0;\n",
        "            color: #555;\n",
        "        }}\n",
        "        .figure-container iframe {{\n",
        "            /* Removed default width: 100%; to allow individual width or auto-sizing */\n",
        "            height: 750px; /* Adjusted default height for plotly figures to prevent flattening */\n",
        "            width: 100%; /* Allow iframe to fill its container */\n",
        "            border: none;\n",
        "            display: block; /* Treat iframe as a block element */\n",
        "            margin: 0 auto; /* Center iframe horizontally */\n",
        "            text-align: center; /* Center iframe text */\n",
        "        }}\n",
        "\n",
        "        .subsection {{\n",
        "            margin-bottom: 20px;\n",
        "            border-bottom: 1px solid #eee;\n",
        "            padding-bottom: 15px;\n",
        "        }}\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"container\">\n",
        "        <h1>Project Report: {repo.name}</h1>\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# Calculate total contributors\n",
        "total_contributors = num_core_devs + num_externals\n",
        "\n",
        "# 2. Project Overview (moved before Project Summary)\n",
        "html_content_parts.append(f\"\"\"\n",
        "        <div class=\"section\">\n",
        "            <h2>Analysis Period</h2>\n",
        "            <p>{overview_description}</p>\n",
        "            <p><b>Acquisition Date:</b> {analysis_run_date}</p>\n",
        "            <p><b>Interval length:</b> {selected_period_str}</p>\n",
        "        </div>\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# 3. Project Summary (moved after Project Overview)\n",
        "html_content_parts.append(f\"\"\"\n",
        "        <div class=\"section\">\n",
        "            <h2>Project Summary</h2>\n",
        "            <p>{summary_description}</p>\n",
        "            <p><b>Repository Name:</b> {repo.name}</p>\n",
        "            <p><b>Description:</b> {repo.description if repo.description else 'No description provided.'}</p>\n",
        "            <p><b>URL:</b> <a href=\"{repo.html_url}\">{repo.html_url}</a></p>\n",
        "            <p><b>Stars:</b> {repo.stargazers_count}</p>\n",
        "            <p><b>Forks:</b> {repo.forks_count}</p>\n",
        "            <p><b>Created At:</b> {repo.created_at.strftime('%Y-%m-%d %H:%M:%S')}</p>\n",
        "            <p><b>Last Updated At:</b> {repo.updated_at.strftime('%Y-%m-%d %H:%M:%S')}</p>\n",
        "            <p><b>Number of contributors:</b> {total_contributors}</p>\n",
        "            <ul>\n",
        "                <li>Project maintainers: {num_core_devs}</li>\n",
        "                <li>External contributors: {num_externals}</li>\n",
        "            </ul>\n",
        "        </div>\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# 4. Inactive Developers\n",
        "inactive_devs_html = f\"\"\"\n",
        "        <div class=\"section\">\n",
        "            <h2>Inactive Developers</h2>\n",
        "            <p>{inactive_devs_description}</p>\n",
        "\"\"\"\n",
        "if not inactive_devs_df.empty:\n",
        "    inactive_devs_html += f\"\"\"\n",
        "            <p>{len(inactive_devs_df)} {inactive_devs_found_text}</p>\n",
        "            <ul>\n",
        "\"\"\"\n",
        "    for index, row in inactive_devs_df.iterrows():\n",
        "        dev_name = row['name'] if row['name'] != 'N/A' else 'Name not available'\n",
        "        inactive_devs_html += f\"                <li>{row['github_login']} ({dev_name})</li>\\n\"\n",
        "else:\n",
        "    inactive_devs_html += f\"            <p>{inactive_devs_none_text}</p>\\n\"\n",
        "inactive_devs_html += \"        </div>\\n\"\n",
        "html_content_parts.append(inactive_devs_html)\n",
        "\n",
        "# 5. All Primitive Events\n",
        "html_content_parts.append(f\"\"\"\n",
        "        <div class=\"section\">\n",
        "            <h2>Events</h2>\n",
        "            <p>{primitive_events_description}</p>\n",
        "            <div class=\"figure-container\">\n",
        "                <iframe src=\"./all_primitive_events.html\"></iframe>\n",
        "            </div>\n",
        "        </div>\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# 6. All Aggregate Events\n",
        "html_content_parts.append(f\"\"\"\n",
        "        <div class=\"section\">\n",
        "            <h2>Categorized events</h2>\n",
        "            <p>{aggregate_events_description}</p>\n",
        "            <div class=\"figure-container\">\n",
        "                <iframe src=\"./all_aggregate_events.html\"></iframe>\n",
        "            </div>\n",
        "        </div>\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# 7. WB\n",
        "html_content_parts.append(f\"\"\"\n",
        "        <div class=\"section\">\n",
        "            <h2>Workload Balance (WB)</h2>\n",
        "            <p>{wbi_description}</p>\n",
        "            <div class=\"figure-container\">\n",
        "                <iframe src=\"./workload_balance.html\" style=\"height: 200px; width: 880px;\"></iframe>\n",
        "            </div>\n",
        "        </div>\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# 8. RB\n",
        "html_content_parts.append(f\"\"\"\n",
        "        <div class=\"section\">\n",
        "            <h2>Resolution Balance (RB)</h2>\n",
        "            <p>{rbi_description}</p>\n",
        "            <div class=\"figure-container\">\n",
        "                <iframe src=\"./resolution_balance.html\" style=\"height: 200px; width: 880px;\"></iframe>\n",
        "            </div>\n",
        "        </div>\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# 9. Project Performance Map\n",
        "html_content_parts.append(f\"\"\"\n",
        "        <div class=\"section\">\n",
        "            <h2>Project tide chart (WB x RB)</h2>\n",
        "            <p>{performance_map_description}</p>\n",
        "            <div class=\"figure-container\">\n",
        "                <iframe src=\"./wb_rb_map.html\" style=\"height: 700px; width: 960px;\"></iframe>\n",
        "            </div>\n",
        "        </div>\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# 10. PRs Close Time section\n",
        "html_content_parts.append(f\"\"\"\n",
        "        <div class=\"section\">\n",
        "            <h2>PR completion time</h2>\n",
        "            <p>{pr_close_time_description}</p>\n",
        "            <div class=\"figure-container\">\n",
        "                <iframe src=\"./pr_close_times_histogram.html\"></iframe>\n",
        "            </div>\n",
        "            <div class=\"figure-container\">\n",
        "                <iframe src=\"./pr_close_time_scatter_plot.html\" style=\"height: 700px;\"></iframe>\n",
        "            </div>\n",
        "            <div class=\"figure-container\">\n",
        "                <iframe src=\"./pr_categories_pie_chart.html\"></iframe>\n",
        "            </div>\n",
        "        </div>\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# 11. Developers Overview - Engagement\n",
        "html_content_parts.append(f\"\"\"\n",
        "        <div class=\"section\">\n",
        "            <h2>Developers Overview</h2>\n",
        "            <div class=\"subsection\">\n",
        "                <h3>Engagement chart</h3>\n",
        "                <p>{engagement_plot_description}</p>\n",
        "                <div class=\"figure-container\">\n",
        "                    <iframe src=\"./engagement_plot.html\" style=\"height: 700px;\"></iframe>\n",
        "                </div>\n",
        "            </div>\n",
        "            <div class=\"subsection\">\n",
        "                <h3>Engagement Magnitude Index (EM)</h3>\n",
        "                <p>{remi_index_description}</p>\n",
        "                <div class=\"figure-container\">\n",
        "                    <iframe src=\"./em_index.html\"></iframe>\n",
        "                </div>\n",
        "            </div>\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# 12. Developers Overview - Delivery\n",
        "html_content_parts.append(f\"\"\"\n",
        "            <div class=\"subsection\">\n",
        "                <h3>Delivery chart</h3>\n",
        "                <p>{delivery_plot_description}</p>\n",
        "                <div class=\"figure-container\">\n",
        "                    <iframe src=\"./delivery_plot.html\" style=\"height: 900px;\"></iframe>\n",
        "                </div>\n",
        "            </div>\n",
        "            <div class=\"subsection\">\n",
        "                <h3>Delivery Magnitude Index (DM)</h3>\n",
        "                <p>{rdmi_index_description}</p>\n",
        "                <div class=\"figure-container\">\n",
        "                    <iframe src=\"./dm_index.html\"></iframe>\n",
        "                </div>\n",
        "            </div>\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# 13. Engagement-Delivery Map\n",
        "html_content_parts.append(f\"\"\"\n",
        "            <div class=\"subsection\">\n",
        "                <h3>Contribution chart</h3>\n",
        "                <p>{engagement_delivery_map_description}</p>\n",
        "                <div class=\"figure-container\">\n",
        "                    <iframe src=\"./engagement_delivery_map.html\" style=\"height: 1000px;\"></iframe>\n",
        "                </div>\n",
        "            </div>\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# 14. Contribution (EM+DM) Plot\n",
        "html_content_parts.append(f\"\"\"\n",
        "            <div class=\"subsection\">\n",
        "                <h3>Contribution rank</h3>\n",
        "                <p>{contribution_plot_description}</p>\n",
        "                <div class=\"figure-container\">\n",
        "                    <iframe src=\"./contribution_em_dm_plot.html\" style=\"height: 700px;\"></iframe>\n",
        "                </div>\n",
        "            </div>\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# 15. Score Plot\n",
        "html_content_parts.append(f\"\"\"\n",
        "            <div class=\"subsection\">\n",
        "                <h3>Contribution score</h3>\n",
        "                <p>{score_plot_description}</p>\n",
        "                <div class=\"figure-container\">\n",
        "                    <iframe src=\"./score_plot.html\"></iframe>\n",
        "                </div>\n",
        "            </div>\n",
        "            <div class=\"subsection\">\n",
        "                <h3>Contribution score percentiles</h3>\n",
        "                <p>{score_percentiles_description}</p>\n",
        "                <div class=\"figure-container\">\n",
        "                    <iframe src=\"./score_percentiles_box_plot.html\"></iframe>\n",
        "                </div>\n",
        "            </div>\n",
        "            <div class=\"subsection\">\n",
        "                <h3>Contribution score histogram</h3>\n",
        "                <p>{score_histogram_description}</p>\n",
        "                <div class=\"figure-container\">\n",
        "                    <iframe src=\"./score_histogram.html\"></iframe>\n",
        "                </div>\n",
        "            </div>\n",
        "            <div class=\"subsection\">\n",
        "                <h3>Score ranges</h3>\n",
        "                <p>{score_proportions_description}</p>\n",
        "                <div class=\"figure-container\">\n",
        "                    <iframe src=\"./score_proportions_pie_chart.html\"></iframe>\n",
        "                </div>\n",
        "            </div>\n",
        "        </div> <!-- Close Developers Overview section -->\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# 16. Aggregate Indices Header\n",
        "html_content_parts.append(f\"\"\"\n",
        "        <div class=\"section\">\n",
        "            <h2>Indices distributions</h2>\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# 18. Quartile Distribution of Key Development Metrics\n",
        "html_content_parts.append(f\"\"\"\n",
        "            <div class=\"subsection\">\n",
        "                <p>{metric_quartiles_description}</p>\n",
        "                <div class=\"figure-container\">\n",
        "                    <iframe src=\"./metric_quartiles_box_plot.html\" style=\"height: 700px;\"></iframe>\n",
        "                </div>\n",
        "            </div>\n",
        "        </div> <!-- Close Aggregate Indices section -->\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# 19. Inactive Developers (Moved to end)\n",
        "inactive_devs_html = f\"\"\"\n",
        "        <div class=\"section\">\n",
        "            <h2>Inactive Developers</h2>\n",
        "            <p>{inactive_devs_description}</p>\n",
        "\"\"\"\n",
        "if not inactive_devs_df.empty:\n",
        "    inactive_devs_html += f\"\"\"\n",
        "            <p>{len(inactive_devs_df)} {inactive_devs_found_text}</p>\n",
        "            <ul>\n",
        "\"\"\"\n",
        "    for index, row in inactive_devs_df.iterrows():\n",
        "        dev_name = row['name'] if row['name'] != 'N/A' else 'Name not available'\n",
        "        inactive_devs_html += f\"                <li>{row['github_login']} ({dev_name})</li>\\n\"\n",
        "else:\n",
        "    inactive_devs_html += f\"            <p>{inactive_devs_none_text}</p>\\n\"\n",
        "inactive_devs_html += \"        </div>\\n\"\n",
        "html_content_parts.append(inactive_devs_html)\n",
        "\n",
        "# 20. Final closing tags\n",
        "html_content_parts.append(\"\"\"\n",
        "    </div> <!-- Close container -->\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# Join all parts and write to file\n",
        "final_html_content = \"\".join(html_content_parts)\n",
        "\n",
        "html_file_path = os.path.join(output_folder, 'index.html')\n",
        "\n",
        "with open(html_file_path, 'w') as f:\n",
        "    f.write(final_html_content)\n",
        "\n",
        "print(f\"Finalized HTML report created at: {html_file_path}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f58485f3"
      },
      "source": [
        "# Task\n",
        "Create a DataFrame named `df_daily_events` within the `time-plot` cell (`GWv7aCkB9y7s`). This DataFrame should have each row representing one of the primitive event types (issues opened, issues reopened, comments, PRs opened, PRs merged, scaled additions, scaled deletions) and each column representing a day within the analysis period, showing the count of that event type for that day. After creating the DataFrame, also generate a time series plot showing the daily counts for each event type."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adbe92a2"
      },
      "source": [
        "## Create Daily Event DataFrame in `time-plot` cell\n",
        "\n",
        "### Subtask:\n",
        "Create a DataFrame named `df_daily_events` and a time series plot showing daily event counts within the analysis period.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11f80be2"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   A DataFrame, `df_daily_events`, was successfully created. This DataFrame organizes daily counts for seven distinct event types: issues opened, issues reopened, comments, pull requests opened, pull requests merged, scaled additions, and scaled deletions. Each row represents an event type, and each column corresponds to a specific day within the analysis period, displaying the count for that event type on that day.\n",
        "*   A time series plot was generated, visualizing the daily counts for each of the aforementioned event types, allowing for a temporal overview of project activity.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The time series plot of daily event counts provides a clear visual representation of activity trends over time. This can help in identifying periods of high or low activity, potential bottlenecks, or the impact of specific project milestones.\n",
        "*   Further analysis could involve correlating these event trends with external factors or project phases to understand the drivers behind changes in development activity.\n"
      ]
    }
  ]
}